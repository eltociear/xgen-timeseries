{
  "about": [],
  "archive/ConversionGuideEmcee": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport emcee",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "az.style.use(\"XGenTS-darkgrid\")",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "J = 8\ny_obs = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "def log_prior_8school(theta):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    # Half-cauchy prior, hwhm=25\n    if tau < 0:\n        return -np.inf\n    prior_tau = -np.log(tau**2 + 25**2)\n    prior_mu = -((mu / 10) ** 2)  # normal prior, loc=0, scale=10\n    prior_eta = -np.sum(eta**2)  # normal prior, loc=0, scale=1\n    return prior_mu + prior_tau + prior_eta\n\n\ndef log_likelihood_8school(theta, y, s):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    return -(((mu + tau * eta - y) / s) ** 2)\n\n\ndef lnprob_8school(theta, y, s):\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, s)\n    like = np.sum(like_vect)\n    return like + prior",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "nwalkers = 40  # called chains in XGenTS\nndim = J + 2\ndraws = 1500\npos = np.random.normal(size=(nwalkers, ndim))\npos[:, 1] = np.absolute(pos[:, 1])\nsampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob_8school, args=(y_obs, sigma))\nsampler.run_mcmc(pos, draws);",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "# define variable names, it cannot be inferred from emcee\nvar_names = [\"mu\", \"tau\"] + [\"eta{}\".format(i) for i in range(J)]\nidata1 = az.from_emcee(sampler, var_names=var_names)\nidata1",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "idata1.sel(draw=slice(100, None))",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "az.plot_posterior(idata1, var_names=[\"mu\", \"tau\", \"eta4\"])",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "idata2 = az.from_emcee(sampler, slices=[0, 1, slice(2, None)])\nidata2",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "structuring-the-posterior-as-multidimensional-variables",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Structuring the posterior as multidimensional variables"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "az.plot_trace(idata2, var_names=[\"var_2\"], coords={\"var_2_dim_0\": 4});",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "structuring-the-posterior-as-multidimensional-variables",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Structuring the posterior as multidimensional variables"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "def lnprob_8school_blobs(theta, y, s):\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, s)\n    like = np.sum(like_vect)\n    return like + prior, like_vect\n\n\nsampler_blobs = emcee.EnsembleSampler(\n    nwalkers,\n    ndim,\n    lnprob_8school_blobs,\n    args=(y_obs, sigma),\n)\nsampler_blobs.run_mcmc(pos, draws);",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "blobs-unlock-sample-stats-posterior-predictive-and-miscellanea",
        "headings": [
          "Converting emcee objects to InferenceData",
          "blobs: unlock sample stats, posterior predictive and miscellanea"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "dims = {\"eta\": [\"school\"], \"log_likelihood\": [\"school\"]}\nidata3 = az.from_emcee(\n    sampler_blobs,\n    var_names=[\"mu\", \"tau\", \"eta\"],\n    slices=[0, 1, slice(2, None)],\n    blob_names=[\"log_likelihood\"],\n    dims=dims,\n    coords={\"school\": range(8)},\n)\nidata3",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "slice"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "blobs-unlock-sample-stats-posterior-predictive-and-miscellanea",
        "headings": [
          "Converting emcee objects to InferenceData",
          "blobs: unlock sample stats, posterior predictive and miscellanea"
        ]
      },
      "doc_lineno": 250002
    },
    {
      "source": "sampler_blobs.blobs[0, 1]",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 280002
    },
    {
      "source": "def lnprob_8school_blobs(theta, y, sigma):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, sigma)\n    like = np.sum(like_vect)\n    # store pointwise log likelihood, useful for model comparison with az.loo or az.waic\n    # and posterior predictive samples as blobs\n    return like + prior, (like_vect, np.random.normal((mu + tau * eta), sigma))\n\n\nsampler_blobs = emcee.EnsembleSampler(\n    nwalkers,\n    ndim,\n    lnprob_8school_blobs,\n    args=(y_obs, sigma),\n)\nsampler_blobs.run_mcmc(pos, draws)\n\ndims = {\"eta\": [\"school\"], \"log_likelihood\": [\"school\"], \"y\": [\"school\"]}\nidata4 = az.from_emcee(\n    sampler_blobs,\n    var_names=[\"mu\", \"tau\", \"eta\"],\n    slices=[0, 1, slice(2, None)],\n    arg_names=[\"y\", \"sigma\"],\n    arg_groups=[\"observed_data\", \"constant_data\"],\n    blob_names=[\"log_likelihood\", \"y\"],\n    blob_groups=[\"log_likelihood\", \"posterior_predictive\"],\n    dims=dims,\n    coords={\"school\": range(8)},\n)\nidata4",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "slice"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "az.plot_ppc(idata4, var_names=[\"y\"], alpha=0.3, num_pp_samples=200);",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "%load_ext watermark\n%watermark -n -u -v -iv -w",
      "names": [],
      "example": {
        "document": "archive/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 320002
    }
  ],
  "archive/CreatingInferenceData": [
    {
      "source": "import xgen as xg\nimport numpy as np",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "creating-inferencedata",
        "headings": [
          "Creating InferenceData"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "size = 100\ndataset = az.convert_to_inference_data(np.random.randn(size))\ndataset",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-1d-numpy-array",
        "headings": [
          "Creating InferenceData",
          "From 1D numpy array"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "shape = (1, 2, 3, 4, 5)\ndataset = az.convert_to_inference_data(np.random.randn(*shape))\ndataset",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-nd-numpy-array",
        "headings": [
          "Creating InferenceData",
          "From nD numpy array"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "datadict = {\n    \"a\": np.random.randn(100),\n    \"b\": np.random.randn(1, 100, 10),\n    \"c\": np.random.randn(1, 100, 3, 4),\n}\ndataset = az.convert_to_inference_data(datadict)\ndataset",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-a-dictionary",
        "headings": [
          "Creating InferenceData",
          "From a dictionary"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "datadict = {\n    \"a\": np.random.randn(100),\n    \"b\": np.random.randn(1, 100, 10),\n    \"c\": np.random.randn(1, 100, 3, 4),\n}\ncoords = {\"c1\": np.arange(3), \"c2\": np.arange(4), \"b1\": np.arange(10)}\ndims = {\"b\": [\"b1\"], \"c\": [\"c1\", \"c2\"]}\n\ndataset = az.convert_to_inference_data(datadict, coords=coords, dims=dims)\ndataset",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-dictionary-with-coords-and-dims",
        "headings": [
          "Creating InferenceData",
          "From dictionary with coords and dims"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "import pandas as pd\nimport xarray as xr\n\ndata = np.random.rand(100, 2)\ndf = pd.DataFrame({\"a\": data[:, 0], \"b\": data[:, 1]})\ndf[\"chain\"] = 0\ndf[\"draw\"] = np.arange(len(df), dtype=int)\ndf = df.set_index([\"chain\", \"draw\"])\nxdata = xr.Dataset.from_dataframe(df)\n\ndataset = az.InferenceData(posterior=xdata)\ndataset",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "xarray",
            "Dataset",
            "from_dataframe"
          ],
          "code_str": "xr.Dataset.from_dataframe",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "xarray.Dataset.from_dataframe"
        }
      ],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-dataframe",
        "headings": [
          "Creating InferenceData",
          "From Dataframe"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "import pymc3 as pm\n\ndraws = 500\nchains = 2\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-pymc3",
        "headings": [
          "Creating InferenceData",
          "From PyMC3"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "with pm.Model() as model:\n    mu = pm.Normal(\"mu\", mu=0, sd=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta_tilde = pm.Normal(\"theta_tilde\", mu=0, sd=1, shape=eight_school_data[\"J\"])\n    theta = pm.Deterministic(\"theta\", mu + tau * theta_tilde)\n    pm.Normal(\"obs\", mu=theta, sd=eight_school_data[\"sigma\"], observed=eight_school_data[\"y\"])\n\n    trace = pm.sample(draws, chains=chains)\n    prior = pm.sample_prior_predictive()\n    posterior_predictive = pm.sample_posterior_predictive(trace)\n\n    pm_data = az.from_pymc3(\n        trace=trace,\n        prior=prior,\n        posterior_predictive=posterior_predictive,\n        coords={\"school\": np.arange(eight_school_data[\"J\"])},\n        dims={\"theta\": [\"school\"], \"theta_tilde\": [\"school\"]},\n    )\npm_data",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-pymc3",
        "headings": [
          "Creating InferenceData",
          "From PyMC3"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "import pystan\n\nschools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\nstan_model = pystan.StanModel(model_code=schools_code)\nfit = stan_model.sampling(data=eight_school_data, control={\"adapt_delta\": 0.9})\n\nstan_data = az.from_pystan(\n    posterior=fit,\n    posterior_predictive=\"y_hat\",\n    observed_data=[\"y\"],\n    log_likelihood={\"y\": \"log_lik\"},\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\n\nstan_data",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-pystan",
        "headings": [
          "Creating InferenceData",
          "From PyStan"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "import pyro\nimport pyro.distributions as dist\nimport torch\nfrom pyro.infer import MCMC, NUTS, Predictive\n\npyro.enable_validation(True)\npyro.set_rng_seed(0)\n\ndraws = 500\nchains = 2\neight_school_data = {\n    \"J\": 8,\n    \"y\": torch.tensor([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": torch.tensor([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\n\ndef model(J, sigma, y=None):\n    mu = pyro.sample(\"mu\", dist.Normal(0, 5))\n    tau = pyro.sample(\"tau\", dist.HalfCauchy(5))\n    with pyro.plate(\"J\", J):\n        theta_tilde = pyro.sample(\"theta_tilde\", dist.Normal(0, 1))\n        theta = mu + tau * theta_tilde\n        return pyro.sample(\"obs\", dist.Normal(theta, sigma), obs=y)\n\n\nnuts_kernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\nmcmc = MCMC(\n    nuts_kernel,\n    num_samples=draws,\n    warmup_steps=draws,\n    num_chains=chains,\n    disable_progbar=True,\n)\nmcmc.run(**eight_school_data)\nposterior_samples = mcmc.get_samples()\nposterior_predictive = Predictive(model, posterior_samples)(\n    eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\nprior = Predictive(model, num_samples=500)(eight_school_data[\"J\"], eight_school_data[\"sigma\"])\n\npyro_data = az.from_pyro(\n    mcmc,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\"theta\": [\"school\"]},\n)\npyro_data",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-pyro",
        "headings": [
          "Creating InferenceData",
          "From Pyro"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "from cmdstanpy import CmdStanModel\n\nschools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nwith open(\"./eight_school.stan\", \"w\") as f:\n    print(schools_code, file=f)\n\nstan_file = \"./eight_school.stan\"\nstan_model = CmdStanModel(stan_file=stan_file)\nstan_model.compile()\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\nstan_fit = stan_model.sample(data=eight_school_data)\n\ncmdstanpy_data = az.from_cmdstanpy(\n    posterior=stan_fit,\n    posterior_predictive=\"y_hat\",\n    observed_data={\"y\": eight_school_data[\"y\"]},\n    log_likelihood=\"log_lik\",\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ncmdstanpy_data",
      "names": [
        {
          "import_components": [
            "open"
          ],
          "code_str": "open",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "open"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-cmdstanpy",
        "headings": [
          "Creating InferenceData",
          "From CmdStanPy"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "# save for CmdStan example (needs CmdStanPy run)\nstan_fit.save_csvfiles(dir=\"sample_data\")",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 260002
    },
    {
      "source": "schools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nwith open(\"./eight_school.stan\", \"w\") as f:\n    print(schools_code, file=f)",
      "names": [
        {
          "import_components": [
            "open"
          ],
          "code_str": "open",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "open"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "eight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 280002
    },
    {
      "source": "import pystan\n\npystan.stan_rdump(eight_school_data, \"./eight_school.data.R\")",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "# Bash shell\n#\n# $ cd cmdstan\n# $ make build\n# $ make path/to/eight_school\n# $ cd path/to\n# $ for i in {1..4}\n#   do\n#     ./eight_school sample random seed=12345 \\\n#       id=$i data file=eight_school.data.R \\\n#       output file=sample_data/eight_school_samples-$i.csv &\n#   done\n# $",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 300002
    },
    {
      "source": "# Let's use .stan and .csv files created/saved by the CmdStanPy procedure\n\n# glob string\nposterior_glob = \"sample_data/eight_school-*-[0-9].csv\"\n# list of paths\n# posterior_list =  [\n#     \"sample_data/eight_school-*-1.csv\",\n#     \"sample_data/eight_school-*-2.csv\",\n#     \"sample_data/eight_school-*-3.csv\",\n#     \"sample_data/eight_school-*-4.csv\",\n# ]\n\nobs_data_path = \"./eight_school.data.R\"\n\ncmdstan_data = az.from_cmdstan(\n    posterior=posterior_glob,\n    posterior_predictive=\"y_hat\",\n    observed_data=obs_data_path,\n    observed_data_var=\"y\",\n    log_likelihood=\"log_lik\",\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ncmdstan_data",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "import numpyro\nimport numpyro.distributions as dist\n\nfrom jax.random import PRNGKey\nfrom numpyro.distributions.transforms import AffineTransform\nfrom numpyro.infer import MCMC, NUTS, Predictive\n\nnumpyro.set_host_device_count(4)\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\n\ndef model(J, sigma, y=None):\n    mu = numpyro.sample(\"mu\", dist.Normal(0, 5))\n    tau = numpyro.sample(\"tau\", dist.HalfCauchy(5))\n    # use non-centered reparameterization\n    theta = numpyro.sample(\n        \"theta\",\n        dist.TransformedDistribution(dist.Normal(np.zeros(J), 1), AffineTransform(mu, tau)),\n    )\n    numpyro.sample(\"y\", dist.Normal(theta, sigma), obs=y)\n\n\nkernel = NUTS(model)\nmcmc = MCMC(kernel, num_warmup=500, num_samples=500, num_chains=4, chain_method=\"parallel\")\nmcmc.run(PRNGKey(0), **eight_school_data, extra_fields=[\"num_steps\", \"energy\"])\nposterior_samples = mcmc.get_samples()\nposterior_predictive = Predictive(model, posterior_samples)(\n    PRNGKey(1), eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\nprior = Predictive(model, num_samples=500)(\n    PRNGKey(2), eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\n\nnumpyro_data = az.from_numpyro(\n    mcmc,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\"theta\": [\"school\"]},\n)\nnumpyro_data",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "from-numpyro",
        "headings": [
          "Creating InferenceData",
          "From NumPyro"
        ]
      },
      "doc_lineno": 330002
    },
    {
      "source": "import pyjags",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "import-package",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Import Package"
        ]
      },
      "doc_lineno": 360002
    },
    {
      "source": "eight_school_prior_model_code = \"\"\" \nmodel {\n    mu ~ dnorm(0.0, 1.0/25)\n    tau ~ dt(0.0, 1.0/25, 1.0) T(0, )\n    for (j in 1:J) {\n        theta_tilde[j] ~ dnorm(0.0, 1.0)\n    }\n}\n\"\"\"",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "prior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Prior Model"
        ]
      },
      "doc_lineno": 390002
    },
    {
      "source": "eight_school_posterior_model_code = \"\"\" \nmodel {\n    mu ~ dnorm(0.0, 1.0/25)\n    tau ~ dt(0.0, 1.0/25, 1.0) T(0, )\n    for (j in 1:J) {\n        theta_tilde[j] ~ dnorm(0.0, 1.0)\n        y[j] ~ dnorm(mu + tau * theta_tilde[j], 1.0/(sigma[j]^2))\n        log_like[j] = logdensity.norm(y[j], mu + tau * theta_tilde[j], 1.0/(sigma[j]^2))\n    }\n}\n\"\"\"",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "posterior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Posterior Model"
        ]
      },
      "doc_lineno": 410002
    },
    {
      "source": "parameters = [\"mu\", \"tau\", \"theta_tilde\"]\nvariables = parameters + [\"log_like\"]",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "posterior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Posterior Model"
        ]
      },
      "doc_lineno": 420002
    },
    {
      "source": "jags_prior_model = pyjags.Model(\n    code=eight_school_prior_model_code, data={\"J\": 8}, chains=4, threads=4, chains_per_thread=1\n)",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "id2",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Construct JAGS Model and Run Adaptation Steps",
          "Prior Model"
        ]
      },
      "doc_lineno": 450002
    },
    {
      "source": "jags_posterior_model = pyjags.Model(\n    code=eight_school_posterior_model_code,\n    data=eight_school_data,\n    chains=4,\n    threads=4,\n    chains_per_thread=1,\n)",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "id3",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Construct JAGS Model and Run Adaptation Steps",
          "Posterior Model"
        ]
      },
      "doc_lineno": 470002
    },
    {
      "source": "jags_prior_samples = jags_prior_model.sample(5000 + 1000, vars=parameters)\njags_posterior_samples = jags_posterior_model.sample(5000 + 1000, vars=variables)",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "draw-1000-burn-in-samples-and-5000-actual-samples-per-chain",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Draw 1000 Burn-In Samples and 5000 Actual Samples per Chain"
        ]
      },
      "doc_lineno": 490002
    },
    {
      "source": "pyjags_data = az.from_pyjags(\n    posterior=jags_posterior_samples,\n    prior=jags_prior_samples,\n    log_likelihood={\"y\": \"log_like\"},\n    save_warmup=True,\n    warmup_iterations=1000,\n)\npyjags_data",
      "names": [],
      "example": {
        "document": "archive/CreatingInferenceData",
        "ref_id": "convert-pyjags-samples-dictionary-to-xgents-inference-data-object",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Convert PyJAGS Samples Dictionary to XGenTS Inference Data Object"
        ]
      },
      "doc_lineno": 510002
    }
  ],
  "archive/Introduction": [
    {
      "source": "import xgen as xg\ndataset = xg.dataset.load('uk_dale')",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "installation-xgents-quickstart",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "az.plot_posterior(np.random.randn(100_000));",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "get-started-with-plotting",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Get started with plotting"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "size = (10, 50)\naz.plot_forest(\n    {\n        \"normal\": np.random.randn(*size),\n        \"gumbel\": np.random.gumbel(size=size),\n        \"student t\": np.random.standard_t(df=6, size=size),\n        \"exponential\": np.random.exponential(size=size),\n    }\n);",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "get-started-with-plotting",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Get started with plotting"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "az.rcParams[\"stats.hdi_prob\"] = 0.90",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "import pymc3 as pm\n\nJ = 8\ny = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])\nschools = np.array(\n    [\n        \"Choate\",\n        \"Deerfield\",\n        \"Phillips Andover\",\n        \"Phillips Exeter\",\n        \"Hotchkiss\",\n        \"Lawrenceville\",\n        \"St. Paul's\",\n        \"Mt. Hermon\",\n    ]\n)",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "with pm.Model() as centered_eight:\n    mu = pm.Normal(\"mu\", mu=0, sd=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta = pm.Normal(\"theta\", mu=mu, sd=tau, shape=J)\n    obs = pm.Normal(\"obs\", mu=theta, sd=sigma, observed=y)\n\n    # This pattern is useful in PyMC3\n    prior = pm.sample_prior_predictive()\n    centered_eight_trace = pm.sample(return_inferencedata=False)\n    posterior_predictive = pm.sample_posterior_predictive(centered_eight_trace)",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "az.plot_autocorr(centered_eight_trace, var_names=[\"mu\", \"tau\"]);",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "data = az.from_pymc3(\n    trace=centered_eight_trace,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    model=centered_eight,\n    coords={\"school\": schools},\n    dims={\"theta\": [\"school\"], \"obs\": [\"school\"]},\n)\ndata",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "convert-to-inferencedata",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams",
          "Convert to InferenceData"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "az.plot_trace(data, compact=False);",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "convert-to-inferencedata",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams",
          "Convert to InferenceData"
        ]
      },
      "doc_lineno": 160002
    },
    {
      "source": "import nest_asyncio\n\nnest_asyncio.apply()",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "import stan  # pystan version 3.4.0\n\n\nschools_code = \"\"\"\ndata {\n  int<lower=0> J;\n  array[J] real y;\n  array[J] real<lower=0> sigma;\n}\n\nparameters {\n  real mu;\n  real<lower=0> tau;\n  array[J] real theta;\n}\n\nmodel {\n  mu ~ normal(0, 5);\n  tau ~ cauchy(0, 5);\n  theta ~ normal(mu, tau);\n  y ~ normal(theta, sigma);\n}\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nschools_dat = {\n    \"J\": 8,\n    \"y\": [28, 8, -3, 7, -1, 1, 18, 12],\n    \"sigma\": [15, 10, 16, 11, 9, 11, 10, 18],\n}\n\nposterior = stan.build(schools_code, data=schools_dat, random_seed=1)\nfit = posterior.sample(num_chains=4, num_samples=1000)",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "az.plot_density(fit, var_names=[\"mu\", \"tau\"]);",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "data = az.from_pystan(\n    posterior=fit,\n    posterior_predictive=\"y_hat\",\n    observed_data=[\"y\"],\n    log_likelihood={\"y\": \"log_lik\"},\n    coords={\"school\": schools},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ndata",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 220002
    },
    {
      "source": "az.plot_pair(\n    data,\n    coords={\"school\": [\"Choate\", \"Deerfield\", \"Phillips Andover\"]},\n    divergences=True,\n);",
      "names": [],
      "example": {
        "document": "archive/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 230002
    }
  ],
  "archive/WorkingWithInferenceData": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport xarray as xr\n\nxr.set_options(display_expand_data=False, display_expand_attrs=False);",
      "names": [
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "xarray",
            "set_options"
          ],
          "code_str": "xr.set_options",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "xarray.set_options"
        }
      ],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "working-with-inferencedata",
        "headings": [
          "Working with InferenceData"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "idata = az.load_XGenTS_data(\"centered_eight\")\nidata",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "working-with-inferencedata",
        "headings": [
          "Working with InferenceData"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "post = idata.posterior\npost",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "get-the-dataset-corresponding-to-a-single-group",
        "headings": [
          "Working with InferenceData",
          "Get the dataset corresponding to a single group"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "post[\"log_tau\"] = np.log(post[\"tau\"])\nidata.posterior",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "add-a-new-variable",
        "headings": [
          "Working with InferenceData",
          "Add a new variable"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "stacked = az.extract(idata)\nstacked",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "combine-chains-and-draws",
        "headings": [
          "Working with InferenceData",
          "Combine chains and draws"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "az.extract(idata, num_samples=100)",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "get-a-random-subset-of-the-samples",
        "headings": [
          "Working with InferenceData",
          "Get a random subset of the samples"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "stacked.mu.values",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "obtain-a-numpy-array-for-a-given-parameter",
        "headings": [
          "Working with InferenceData",
          "Obtain a NumPy array for a given parameter"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "len(idata.observed_data.school)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "get-the-dimension-lengths",
        "headings": [
          "Working with InferenceData",
          "Get the dimension lengths"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "idata.observed_data.school",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "get-coordinate-values",
        "headings": [
          "Working with InferenceData",
          "Get coordinate values"
        ]
      },
      "doc_lineno": 210002
    },
    {
      "source": "idata.sel(chain=[0, 2])",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "get-a-subset-of-chains",
        "headings": [
          "Working with InferenceData",
          "Get a subset of chains"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "idata.sel(draw=slice(100, None))",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "remove-the-first-n-draws-burn-in",
        "headings": [
          "Working with InferenceData",
          "Remove the first n draws (burn-in)"
        ]
      },
      "doc_lineno": 250002
    },
    {
      "source": "idata.sel(draw=slice(100, None), groups=\"posterior\")",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "remove-the-first-n-draws-burn-in",
        "headings": [
          "Working with InferenceData",
          "Remove the first n draws (burn-in)"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "post.mean()",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "compute-posterior-mean-values-along-draw-and-chain-dimensions",
        "headings": [
          "Working with InferenceData",
          "Compute posterior mean values along draw and chain dimensions"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "post.mean(dim=[\"chain\", \"draw\"])",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "compute-posterior-mean-values-along-draw-and-chain-dimensions",
        "headings": [
          "Working with InferenceData",
          "Compute posterior mean values along draw and chain dimensions"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "post[\"mlogtau\"] = post[\"log_tau\"].rolling({\"draw\": 50}).mean()",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 340002
    },
    {
      "source": "post[\"theta_school_diff\"] = post.theta - post.theta.rename(school=\"school_bis\")",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 360002
    },
    {
      "source": "theta_school_diff = theta[:, :, :, None] - theta[:, :, None, :]\n",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 370007
    },
    {
      "source": "post",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 380002
    },
    {
      "source": "post[\"theta_school_diff\"].sel(school=\"Choate\", school_bis=\"Deerfield\")",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 400002
    },
    {
      "source": "school_idx = xr.DataArray([\"Choate\", \"Hotchkiss\", \"Mt. Hermon\"], dims=[\"pairwise_school_diff\"])\nschool_bis_idx = xr.DataArray(\n    [\"Deerfield\", \"Choate\", \"Lawrenceville\"], dims=[\"pairwise_school_diff\"]\n)\npost[\"theta_school_diff\"].sel(school=school_idx, school_bis=school_bis_idx)",
      "names": [
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        },
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        }
      ],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 420002
    },
    {
      "source": "post[\"theta_school_diff\"].sel(\n    school=[\"Choate\", \"Hotchkiss\", \"Mt. Hermon\"],\n    school_bis=[\"Deerfield\", \"Choate\", \"Lawrenceville\"],\n)",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 440002
    },
    {
      "source": "idata_rerun = (\n    idata.sel(chain=[0, 1])\n    .copy()\n    .assign_coords(coords={\"chain\": [4, 5]}, groups=\"posterior_groups\")\n)",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "add-new-chains-using-concat",
        "headings": [
          "Working with InferenceData",
          "Add new chains using concat"
        ]
      },
      "doc_lineno": 470002
    },
    {
      "source": "idata_complete = az.concat(idata, idata_rerun, dim=\"chain\")\nidata_complete.posterior.dims[\"chain\"]",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "add-new-chains-using-concat",
        "headings": [
          "Working with InferenceData",
          "Add new chains using concat"
        ]
      },
      "doc_lineno": 490002
    },
    {
      "source": "rng = np.random.default_rng(3)\nidata.add_groups(\n    {\"predictions\": {\"obs\": rng.normal(size=(4, 500, 2))}},\n    dims={\"obs\": [\"new_school\"]},\n    coords={\"new_school\": [\"Essex College\", \"Moordale\"]},\n)\nidata",
      "names": [],
      "example": {
        "document": "archive/WorkingWithInferenceData",
        "ref_id": "add-groups-to-inferencedata-objects",
        "headings": [
          "Working with InferenceData",
          "Add groups to InferenceData objects"
        ]
      },
      "doc_lineno": 520002
    }
  ],
  "archive/XarrayforXGenTS": [
    {
      "source": "# Load the centered eight schools model\nimport xgen as xg\n\ndata = az.load_XGenTS_data(\"centered_eight\")\ndata",
      "names": [],
      "example": {
        "document": "archive/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "# Get the posterior dataset\nposterior = data.posterior\nposterior",
      "names": [],
      "example": {
        "document": "archive/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "# Get the observed xarray\nobserved_data = data.observed_data\nobserved_data",
      "names": [],
      "example": {
        "document": "archive/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "data = az.load_XGenTS_data(\"centered_eight\")",
      "names": [],
      "example": {
        "document": "archive/XarrayforXGenTS",
        "ref_id": "netcdf",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "NetCDF"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "data.to_netcdf(\"eight_schools_model.nc\")",
      "names": [],
      "example": {
        "document": "archive/XarrayforXGenTS",
        "ref_id": "netcdf",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "NetCDF"
        ]
      },
      "doc_lineno": 130002
    }
  ],
  "archive/index": [
    {
      "source": "from xgen.dataset import load\ndataset = load(\"uk-dale\", streaming=True)\n",
      "names": [],
      "example": {
        "document": "archive/index",
        "ref_id": "xgents-archive",
        "headings": [
          "XGenTS Archive"
        ]
      },
      "doc_lineno": 204
    }
  ],
  "community": [],
  "contributing/architecture": [],
  "contributing/content_structure": [],
  "contributing/contributing_prs": [],
  "contributing/developing_in_docker": [],
  "contributing/diataxis_for_arviz": [],
  "contributing/doc_toolchain": [],
  "contributing/docstrings": [],
  "contributing/how_to_add_to_example_gallery": [],
  "contributing/how_to_release": [],
  "contributing/index": [],
  "contributing/issue_reports": [],
  "contributing/issue_triaging": [],
  "contributing/outreach": [],
  "contributing/plotting_backends": [],
  "contributing/pr_checklist": [],
  "contributing/pr_tutorial": [],
  "contributing/review_prs": [],
  "contributing/running_benchmarks": [],
  "contributing/sphinx_doc_build": [],
  "contributing/syntax_guide": [],
  "contributing/translate": [],
  "contributing/updating_example_data": [],
  "dush/Dask": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport timeit\nimport dask\n\nfrom XGenTS.utils import conditional_jit, Dask",
      "names": [
        {
          "import_components": [
            "timeit"
          ],
          "code_str": "timeit",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "timeit"
        }
      ],
      "example": {
        "document": "dush/Dask",
        "ref_id": "dask-overview",
        "headings": [
          "Dask for XGenTS",
          "Dask overview"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "# optional imports\nfrom dask.distributed import Client\nfrom dask.diagnostics import ResourceProfiler\n\nfrom bokeh.resources import INLINE\nimport bokeh.io\n\nbokeh.io.output_notebook(INLINE)\n\n%reload_ext memory_profiler",
      "names": [
        {
          "import_components": [
            "dask",
            "diagnostics",
            "ResourceProfiler"
          ],
          "code_str": "ResourceProfiler",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "dask.diagnostics.ResourceProfiler"
        },
        {
          "import_components": [
            "bokeh",
            "resources"
          ],
          "code_str": "bokeh.resources",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_from",
          "resolved_location": "bokeh.resources"
        },
        {
          "import_components": [
            "bokeh",
            "resources",
            "INLINE"
          ],
          "code_str": "INLINE",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "bokeh.resources.INLINE"
        },
        {
          "import_components": [
            "bokeh",
            "io"
          ],
          "code_str": "bokeh.io",
          "lineno": 6,
          "end_lineno": 6,
          "context": "import_target",
          "resolved_location": "bokeh.io"
        },
        {
          "import_components": [
            "bokeh",
            "resources",
            "INLINE"
          ],
          "code_str": "INLINE",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "bokeh.resources.INLINE"
        },
        {
          "import_components": [
            "bokeh",
            "io",
            "output_notebook"
          ],
          "code_str": "bokeh.io.output_notebook",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "bokeh.io.output_notebook"
        }
      ],
      "example": {
        "document": "dush/Dask",
        "ref_id": "dask-overview",
        "headings": [
          "Dask for XGenTS",
          "Dask overview"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "client = Client(threads_per_worker=4, n_workers=1, memory_limit=\"1.2GB\")\nclient",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "dask-overview",
        "headings": [
          "Dask for XGenTS",
          "Dask overview"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "array_size = 250_000_000",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "variance-example",
        "headings": [
          "Dask for XGenTS",
          "Dask overview",
          "Variance example"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "%%memit \ndata = np.random.randn(array_size)\nnp.var(data, ddof=1)\ndel data",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "variance-example",
        "headings": [
          "Dask for XGenTS",
          "Dask overview",
          "Variance example"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "%memit data = dask.array.random.normal(size=array_size, chunks=\"auto\")\ndata",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "variance-example",
        "headings": [
          "Dask for XGenTS",
          "Dask overview",
          "Variance example"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "var = dask.array.var(data, ddof=1)\nvar.visualize()",
      "names": [
        {
          "import_components": [
            "dask",
            "array",
            "var"
          ],
          "code_str": "dask.array.var",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "dask.array.var"
        }
      ],
      "example": {
        "document": "dush/Dask",
        "ref_id": "variance-example",
        "headings": [
          "Dask for XGenTS",
          "Dask overview",
          "Variance example"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "with ResourceProfiler(dt=0.25) as rprof:\n    var.compute()\n\nrprof.visualize();",
      "names": [
        {
          "import_components": [
            "dask",
            "diagnostics",
            "ResourceProfiler"
          ],
          "code_str": "ResourceProfiler",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "dask.diagnostics.ResourceProfiler"
        }
      ],
      "example": {
        "document": "dush/Dask",
        "ref_id": "variance-example",
        "headings": [
          "Dask for XGenTS",
          "Dask overview",
          "Variance example"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "del data",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "variance-example",
        "headings": [
          "Dask for XGenTS",
          "Dask overview",
          "Variance example"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "%memit daskdata = dask.array.random.random((10, 1000, 10000), chunks=(10, 1000, 625))\ndaskdata",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "from-dictionary-using-dask-array",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Creating Dask-backed InferenceData objects",
          "From dictionary using dask.array"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "daskdata.visualize()  # Each chunk will follow lazy evaluation",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "from-dictionary-using-dask-array",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Creating Dask-backed InferenceData objects",
          "From dictionary using dask.array"
        ]
      },
      "doc_lineno": 210002
    },
    {
      "source": "datadict = {\"x\": daskdata}\n%memit idata_dask = az.from_dict(posterior=datadict, dims={\"x\": [\"dim_1\"]})\nidata_dask",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "from-dictionary-using-dask-array",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Creating Dask-backed InferenceData objects",
          "From dictionary using dask.array"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "%memit npdata = np.random.rand(10, 1000, 10000)\ndatadict = {\"x\": npdata}\nidata_numpy = az.from_dict(posterior=datadict, dims={\"x\": [\"dim_1\"]})\nidata_numpy",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "executing-xgents-functions-with-dask",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "%%time\n%%memit\n\naz.ess(idata_numpy)",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-ess",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.ess"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "Dask.enable_dask(dask_kwargs={\"dask\": \"parallelized\", \"output_dtypes\": [float]})",
      "names": [
        {
          "import_components": [
            "float"
          ],
          "code_str": "float",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "float"
        }
      ],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-ess",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.ess"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "%%time\n%%memit\n\ness = az.ess(idata_dask)\n\nwith ResourceProfiler(dt=0.25) as rprof:\n    ess.compute()",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-ess",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.ess"
        ]
      },
      "doc_lineno": 320002
    },
    {
      "source": "ess.data_vars[\"x\"].data.visualize()",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-ess",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.ess"
        ]
      },
      "doc_lineno": 340002
    },
    {
      "source": "rprof.visualize()\nDask.disable_dask()",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-ess",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.ess"
        ]
      },
      "doc_lineno": 350002
    },
    {
      "source": "%%time\n%%memit\n\naz.rhat(idata_numpy)",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-rhat",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.rhat "
        ]
      },
      "doc_lineno": 380002
    },
    {
      "source": "Dask.enable_dask(dask_kwargs={\"dask\": \"parallelized\", \"output_dtypes\": [int]})",
      "names": [
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-rhat",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.rhat "
        ]
      },
      "doc_lineno": 390002
    },
    {
      "source": "%%time\n%%memit\n\nrhat = az.rhat(idata_dask, dask_kwargs={\"output_dtypes\": [float]})\n\nwith ResourceProfiler(dt=0.25) as rprof:\n    rhat.compute()",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-rhat",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.rhat "
        ]
      },
      "doc_lineno": 410002
    },
    {
      "source": "rprof.visualize()\nDask.disable_dask()",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-rhat",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.rhat "
        ]
      },
      "doc_lineno": 420002
    },
    {
      "source": "%%time\n%%memit\n\naz.hdi(idata_numpy, hdi_prob=0.68)",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-hdi",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.hdi"
        ]
      },
      "doc_lineno": 440002
    },
    {
      "source": "Dask.enable_dask(dask_kwargs={\"dask\": \"parallelized\", \"output_dtypes\": [float]})",
      "names": [
        {
          "import_components": [
            "float"
          ],
          "code_str": "float",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "float"
        }
      ],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-hdi",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.hdi"
        ]
      },
      "doc_lineno": 450002
    },
    {
      "source": "%%time\n%%memit\n\nhdi = az.hdi(idata_dask, hdi_prob=0.68, dask_gufunc_kwargs={\"output_sizes\": {\"hdi\": 2}})\n\nwith ResourceProfiler(dt=0.25) as rprof:\n    hdi.compute()",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-hdi",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.hdi"
        ]
      },
      "doc_lineno": 470002
    },
    {
      "source": "rprof.visualize()\nDask.disable_dask()\nclient.close()",
      "names": [],
      "example": {
        "document": "dush/Dask",
        "ref_id": "xgents-hdi",
        "headings": [
          "Dask for XGenTS",
          "XGenTS-Dask integration",
          "Executing XGenTS functions with Dask",
          "XGenTS.hdi"
        ]
      },
      "doc_lineno": 480002
    }
  ],
  "dush/Numba": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport timeit\n\nfrom XGenTS.utils import conditional_jit, Numba\nfrom XGenTS.stats.diagnostics import ks_summary",
      "names": [
        {
          "import_components": [
            "timeit"
          ],
          "code_str": "timeit",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "timeit"
        }
      ],
      "example": {
        "document": "dush/Numba",
        "ref_id": "a-simple-example-to-display-the-effectiveness-of-numba",
        "headings": [
          "Numba -  an overview",
          "A simple example to display the effectiveness of Numba"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "data = np.random.randn(1000000)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "a-simple-example-to-display-the-effectiveness-of-numba",
        "headings": [
          "Numba -  an overview",
          "A simple example to display the effectiveness of Numba"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "def variance(data, ddof=0):  # Method to calculate variance without using numba\n    a_a, b_b = 0, 0\n    for i in data:\n        a_a = a_a + i\n        b_b = b_b + i * i\n    var = b_b / (len(data)) - ((a_a / (len(data))) ** 2)\n    var = var * (len(data) / (len(data) - ddof))\n    return var",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "dush/Numba",
        "ref_id": "a-simple-example-to-display-the-effectiveness-of-numba",
        "headings": [
          "Numba -  an overview",
          "A simple example to display the effectiveness of Numba"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "%timeit variance(data, ddof=1)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "a-simple-example-to-display-the-effectiveness-of-numba",
        "headings": [
          "Numba -  an overview",
          "A simple example to display the effectiveness of Numba"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "@conditional_jit\ndef variance_jit(data, ddof=0):  # Calculating variance with numba\n    a_a, b_b = 0, 0\n    for i in data:\n        a_a = a_a + i\n        b_b = b_b + i * i\n    var = b_b / (len(data)) - ((a_a / (len(data))) ** 2)\n    var = var * (len(data) / (len(data) - ddof))\n    return var",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "dush/Numba",
        "ref_id": "a-simple-example-to-display-the-effectiveness-of-numba",
        "headings": [
          "Numba -  an overview",
          "A simple example to display the effectiveness of Numba"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "%timeit variance_jit(data, ddof=1)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "a-simple-example-to-display-the-effectiveness-of-numba",
        "headings": [
          "Numba -  an overview",
          "A simple example to display the effectiveness of Numba"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "%timeit np.var(data, ddof=1)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "a-simple-example-to-display-the-effectiveness-of-numba",
        "headings": [
          "Numba -  an overview",
          "A simple example to display the effectiveness of Numba"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "summary_data = np.random.randn(1000, 100, 10)\nschool = az.load_XGenTS_data(\"centered_eight\").posterior[\"mu\"].values",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "numba-within-xgents",
        "headings": [
          "Numba -  an overview",
          "Numba within XGenTS"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "Numba.disable_numba()\nNumba.numba_flag",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "numba-within-xgents",
        "headings": [
          "Numba -  an overview",
          "Numba within XGenTS"
        ]
      },
      "doc_lineno": 160002
    },
    {
      "source": "%timeit ks_summary(summary_data)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "numba-within-xgents",
        "headings": [
          "Numba -  an overview",
          "Numba within XGenTS"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "%timeit ks_summary(school)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "numba-within-xgents",
        "headings": [
          "Numba -  an overview",
          "Numba within XGenTS"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "Numba.enable_numba()\nNumba.numba_flag",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "numba-within-xgents",
        "headings": [
          "Numba -  an overview",
          "Numba within XGenTS"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "%timeit ks_summary(summary_data)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "numba-within-xgents",
        "headings": [
          "Numba -  an overview",
          "Numba within XGenTS"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "%timeit ks_summary(school)",
      "names": [],
      "example": {
        "document": "dush/Numba",
        "ref_id": "numba-within-xgents",
        "headings": [
          "Numba -  an overview",
          "Numba within XGenTS"
        ]
      },
      "doc_lineno": 210002
    }
  ],
  "dush/computation": [],
  "dush/data_structures": [],
  "dush/index": [
    {
      "source": "instance: 1 # this is the first building in the dataset\nelec_meters: {} # a dictionary where each key is a meter\n  1: site_meter: true # meter 1 measures the whole-building aggregate\n  2: site_meter: true\n  3: submeter_of: 1 # meter 3 is directly downstream of meter 1\n  4: submeter_of: 1\n  5: submeter_of: 2\n  6: submeter_of: 2\n  7: submeter_of: 6\nappliances:\n- {type: kettle, instance: 1, room: kitchen, meters: [3]}\n- {type: washing machine, instance: 1, meters: [4,5\n\n]}\n- {type: fridge, instance: 1, meters: [2]}\n- {type: dish washer, instance: 1, meters: [6]}\n- {type: light, instance: 1, room: kitchen, meters: [7]}\n- {type: light, instance: 2, multiple: true, meters: [6]}\n",
      "names": [],
      "example": {
        "document": "dush/index",
        "ref_id": "dataset-setup-procedure",
        "headings": [
          "Dataset Setup Procedure"
        ]
      },
      "doc_lineno": 84
    }
  ],
  "dush/label_guide": [
    {
      "source": "In [1]: import xgen as xg\n   ...: schools = az.load_XGenTS_data(\"centered_eight\")\n   ...: az.summary(schools)\n   ...: \n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[1], line 1\n----> 1 import xgen as xg\n      2 schools = az.load_XGenTS_data(\"centered_eight\")\n      3 az.summary(schools)\n\nModuleNotFoundError: No module named 'xgen'",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "example-default-labelling",
        "headings": [
          "Label guide",
          "Basic labelling",
          "Example: Default labelling"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [2]: az.plot_trace(schools, var_names=[\"tau\", \"theta\"], coords={\"school\": [\"Choate\", \"St. Paul's\"]}, compact=False);",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "example-label-based-indexing",
        "headings": [
          "Label guide",
          "Basic labelling",
          "Example: Label based indexing"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [3]: import XGenTS.labels as azl\n   ...: labeller = azl.MapLabeller(var_name_map={\"theta\": r\"$\\theta$\"})\n   ...: coords = {\"school\": [\"Deerfield\", \"Hotchkiss\", \"Lawrenceville\"]}\n   ...: \n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[3], line 1\n----> 1 import XGenTS.labels as azl\n      2 labeller = azl.MapLabeller(var_name_map={\"theta\": r\"$\\theta$\"})\n      3 coords = {\"school\": [\"Deerfield\", \"Hotchkiss\", \"Lawrenceville\"]}\n\nModuleNotFoundError: No module named 'XGenTS'\n\nIn [4]: az.plot_posterior(schools, var_names=\"theta\", coords=coords, labeller=labeller, ref_val=5);",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "example-using-the-labeller-argument",
        "headings": [
          "Label guide",
          "Basic labelling",
          "Example: Using the labeller argument"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [5]: var_order = [\"theta\", \"mu\", \"tau\"]",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "sorting-variable-names",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Sorting variable names"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [6]: az.summary(schools, var_names=var_order)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[6], line 1\n----> 1 az.summary(schools, var_names=var_order)\n\nNameError: name 'az' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "sorting-variable-names",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Sorting variable names"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [7]: schools.posterior = schools.posterior[var_order]\n   ...: az.summary(schools)\n   ...: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[7], line 1\n----> 1 schools.posterior = schools.posterior[var_order]\n      2 az.summary(schools)\n\nNameError: name 'schools' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "sorting-variable-names",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Sorting variable names"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [8]: school_means = schools.posterior[\"theta\"].mean((\"chain\", \"draw\"))\n   ...: school_means\n   ...: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[8], line 1\n----> 1 school_means = schools.posterior[\"theta\"].mean((\"chain\", \"draw\"))\n      2 school_means\n\nNameError: name 'schools' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "example-sorting-the-schools-by-mean",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Example: Sorting the schools by mean"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [9]: sorted_schools = schools.posterior[\"school\"].sortby(school_means)\n   ...: az.summary(schools, var_names=\"theta\", coords={\"school\": sorted_schools})\n   ...: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[9], line 1\n----> 1 sorted_schools = schools.posterior[\"school\"].sortby(school_means)\n      2 az.summary(schools, var_names=\"theta\", coords={\"school\": sorted_schools})\n\nNameError: name 'schools' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "example-sorting-the-schools-by-mean",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Example: Sorting the schools by mean"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [10]: schools.posterior = schools.posterior.sortby(school_means)\n   ....: az.summary(schools, var_names=\"theta\")\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[10], line 1\n----> 1 schools.posterior = schools.posterior.sortby(school_means)\n      2 az.summary(schools, var_names=\"theta\")\n\nNameError: name 'schools' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "example-sorting-the-schools-by-mean",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Example: Sorting the schools by mean"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [11]: from numpy.random import default_rng\n   ....: import pandas as pd\n   ....: rng = default_rng()\n   ....: samples = rng.normal(size=(4, 500, 2, 3, 4))\n   ....: coords = {\n   ....:     \"subject\": [\"ecoli\", \"pseudomonas\", \"clostridium\"],\n   ....:     \"date\": [\"1-3-2020\", \"2-4-2020\", \"1-5-2020\", \"1-6-2020\"],\n   ....:     \"experiment\": [1, 2]\n   ....: }\n   ....: experiments = az.from_dict(\n   ....:     posterior={\"b\": samples}, dims={\"b\": [\"experiment\", \"subject\", \"date\"]}, coords=coords\n   ....: )\n   ....: experiments.posterior\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[11], line 10\n      4 samples = rng.normal(size=(4, 500, 2, 3, 4))\n      5 coords = {\n      6     \"subject\": [\"ecoli\", \"pseudomonas\", \"clostridium\"],\n      7     \"date\": [\"1-3-2020\", \"2-4-2020\", \"1-5-2020\", \"1-6-2020\"],\n      8     \"experiment\": [1, 2]\n      9 }\n---> 10 experiments = az.from_dict(\n     11     posterior={\"b\": samples}, dims={\"b\": [\"experiment\", \"subject\", \"date\"]}, coords=coords\n     12 )\n     13 experiments.posterior\n\nNameError: name 'az' is not defined",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "pandas"
        }
      ],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "sorting-dimensions",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Sorting dimensions"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [12]: az.summary(experiments)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[12], line 1\n----> 1 az.summary(experiments)\n\nNameError: name 'az' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "sorting-dimensions",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Sorting dimensions"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [13]: dim_order = (\"chain\", \"draw\", \"subject\", \"date\", \"experiment\")\n\nIn [14]: experiments = experiments.posterior.transpose(*dim_order)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[14], line 1\n----> 1 experiments = experiments.posterior.transpose(*dim_order)\n\nNameError: name 'experiments' is not defined\n\nIn [15]: az.summary(experiments)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[15], line 1\n----> 1 az.summary(experiments)\n\nNameError: name 'az' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "sorting-dimensions",
        "headings": [
          "Label guide",
          "Sorting labels",
          "Sorting dimensions"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [16]: az.summary(schools, labeller=azl.IdxLabeller())\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[16], line 1\n----> 1 az.summary(schools, labeller=azl.IdxLabeller())\n\nNameError: name 'az' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "labeling-with-indexes",
        "headings": [
          "Label guide",
          "Labeling with indexes"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [17]: az.summary(schools.isel(school=[2, 5, 7]), labeller=azl.IdxLabeller())\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[17], line 1\n----> 1 az.summary(schools.isel(school=[2, 5, 7]), labeller=azl.IdxLabeller())\n\nNameError: name 'az' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "labeling-with-indexes",
        "headings": [
          "Label guide",
          "Labeling with indexes"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [18]: schools2 = az.load_XGenTS_data(\"non_centered_eight\")\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[18], line 1\n----> 1 schools2 = az.load_XGenTS_data(\"non_centered_eight\")\n\nNameError: name 'az' is not defined\n\nIn [19]: az.plot_forest(\n   ....:     (schools, schools2),\n   ....:     model_names=(\"centered\", \"non_centered\"),\n   ....:     coords={\"school\": [\"Deerfield\", \"Lawrenceville\", \"Mt. Hermon\"]},\n   ....:     figsize=(10,7),\n   ....:     labeller=azl.DimCoordLabeller(),\n   ....:     legend=True\n   ....: );\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[19], line 1\n----> 1 az.plot_forest(\n      2     (schools, schools2),\n      3     model_names=(\"centered\", \"non_centered\"),\n      4     coords={\"school\": [\"Deerfield\", \"Lawrenceville\", \"Mt. Hermon\"]},\n      5     figsize=(10,7),\n      6     labeller=azl.DimCoordLabeller(),\n      7     legend=True\n      8 );\n\nNameError: name 'az' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "labeller-mixtures",
        "headings": [
          "Label guide",
          "Labeller mixtures"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [20]: MixtureLabeller = azl.mix_labellers((azl.DimCoordLabeller, azl.NoModelLabeller))\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[20], line 1\n----> 1 MixtureLabeller = azl.mix_labellers((azl.DimCoordLabeller, azl.NoModelLabeller))\n\nNameError: name 'azl' is not defined\n\nIn [21]: az.plot_forest(\n   ....:     (schools, schools2),\n   ....:     model_names=(\"centered\", \"non_centered\"),\n   ....:     coords={\"school\": [\"Deerfield\", \"Lawrenceville\", \"Mt. Hermon\"]},\n   ....:     figsize=(10,7),\n   ....:     labeller=MixtureLabeller(),\n   ....:     legend=True\n   ....: );\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[21], line 1\n----> 1 az.plot_forest(\n      2     (schools, schools2),\n      3     model_names=(\"centered\", \"non_centered\"),\n      4     coords={\"school\": [\"Deerfield\", \"Lawrenceville\", \"Mt. Hermon\"]},\n      5     figsize=(10,7),\n      6     labeller=MixtureLabeller(),\n      7     legend=True\n      8 );\n\nNameError: name 'az' is not defined",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "labeller-mixtures",
        "headings": [
          "Label guide",
          "Labeller mixtures"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [22]: from numpy.random import default_rng\n\nIn [23]: import numpy as np\n\nIn [24]: import xarray as xr\n---------------------------------------------------------------------------\nModuleNotFoundError                       Traceback (most recent call last)\nCell In[24], line 1\n----> 1 import xarray as xr\n\nModuleNotFoundError: No module named 'xarray'\n\nIn [25]: rng = default_rng()\n\nIn [26]: cov = rng.normal(size=(4, 500, 3, 3))\n\nIn [27]: cov = np.einsum(\"...ij,...kj\", cov, cov)\n\nIn [28]: cov[:, :, [0, 1, 2], [0, 1, 2]] = 1\n\nIn [29]: subjects = [\"ecoli\", \"pseudomonas\", \"clostridium\"]\n\nIn [30]: idata = az.from_dict(\n   ....:     {\"cov\": cov},\n   ....:     dims={\"cov\": [\"subject\", \"subject bis\"]},\n   ....:     coords={\"subject\": subjects, \"subject bis\": subjects}\n   ....: )\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[30], line 1\n----> 1 idata = az.from_dict(\n      2     {\"cov\": cov},\n      3     dims={\"cov\": [\"subject\", \"subject bis\"]},\n      4     coords={\"subject\": subjects, \"subject bis\": subjects}\n      5 )\n\nNameError: name 'az' is not defined\n\nIn [31]: idata.posterior\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[31], line 1\n----> 1 idata.posterior\n\nNameError: name 'idata' is not defined",
      "names": [
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "xarray"
        }
      ],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "custom-labellers",
        "headings": [
          "Label guide",
          "Custom labellers"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [32]: coords = {\n   ....:     'subject': xr.DataArray(\n   ....:         [\"ecoli\", \"ecoli\", \"pseudomonas\"], dims=['pointwise_sel']\n   ....:     ),\n   ....:     'subject bis': xr.DataArray(\n   ....:         [\"pseudomonas\", \"clostridium\", \"clostridium\"], dims=['pointwise_sel']\n   ....:     )\n   ....: }\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[32], line 2\n      1 coords = {\n----> 2     'subject': xr.DataArray(\n      3         [\"ecoli\", \"ecoli\", \"pseudomonas\"], dims=['pointwise_sel']\n      4     ),\n      5     'subject bis': xr.DataArray(\n      6         [\"pseudomonas\", \"clostridium\", \"clostridium\"], dims=['pointwise_sel']\n      7     )\n      8 }\n\nNameError: name 'xr' is not defined\n\nIn [33]: idata.posterior.sel(coords)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[33], line 1\n----> 1 idata.posterior.sel(coords)\n\nNameError: name 'idata' is not defined",
      "names": [
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        },
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        }
      ],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "custom-labellers",
        "headings": [
          "Label guide",
          "Custom labellers"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [34]: az.plot_posterior(idata, coords=coords);",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "custom-labellers",
        "headings": [
          "Label guide",
          "Custom labellers"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [35]: coords_ds = xr.Dataset(coords)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[35], line 1\n----> 1 coords_ds = xr.Dataset(coords)\n\nNameError: name 'xr' is not defined\n\nIn [36]: class NonIdxCoordLabeller(azl.BaseLabeller):\n   ....:     \"\"\"Use non indexing coordinates as labels.\"\"\"\n   ....:     def __init__(self, coords_ds):\n   ....:         self.coords_ds = coords_ds\n   ....:     def sel_to_str(self, sel, isel):\n   ....:         new_sel = {k: v.values for k, v in self.coords_ds.sel(sel).items()}\n   ....:         return super().sel_to_str(new_sel, new_sel)\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[36], line 1\n----> 1 class NonIdxCoordLabeller(azl.BaseLabeller):\n      2     \"\"\"Use non indexing coordinates as labels.\"\"\"\n      3     def __init__(self, coords_ds):\n\nNameError: name 'azl' is not defined\n\nIn [37]: labeller = NonIdxCoordLabeller(coords_ds)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[37], line 1\n----> 1 labeller = NonIdxCoordLabeller(coords_ds)\n\nNameError: name 'NonIdxCoordLabeller' is not defined\n\nIn [38]: az.plot_posterior(idata, coords=coords, labeller=labeller);",
      "names": [
        {
          "import_components": [
            "xarray",
            "Dataset"
          ],
          "code_str": "xr.Dataset",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "xarray.Dataset"
        },
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "super"
        }
      ],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "custom-labellers",
        "headings": [
          "Label guide",
          "Custom labellers"
        ]
      },
      "doc_lineno": 1
    },
    {
      "source": "In [39]: class NonIdxCoordLabeller(azl.BaseLabeller):\n   ....:     \"\"\"Use non indexing coordinates as labels.\"\"\"\n   ....:     def __init__(self, coords_ds):\n   ....:         self.coords_ds = coords_ds\n   ....:     def make_label_vert(self, var_name, sel, isel):\n   ....:         coords_ds_subset = self.coords_ds.sel(sel)\n   ....:         subj = coords_ds_subset[\"subject\"].values\n   ....:         subj_bis = coords_ds_subset[\"subject bis\"].values\n   ....:         return f\"Correlation between subjects\\n{subj} & {subj_bis}\"\n   ....: \n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[39], line 1\n----> 1 class NonIdxCoordLabeller(azl.BaseLabeller):\n      2     \"\"\"Use non indexing coordinates as labels.\"\"\"\n      3     def __init__(self, coords_ds):\n\nNameError: name 'azl' is not defined\n\nIn [40]: labeller = NonIdxCoordLabeller(coords_ds)\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[40], line 1\n----> 1 labeller = NonIdxCoordLabeller(coords_ds)\n\nNameError: name 'NonIdxCoordLabeller' is not defined\n\nIn [41]: az.plot_posterior(idata, coords=coords, labeller=labeller);",
      "names": [],
      "example": {
        "document": "dush/label_guide",
        "ref_id": "custom-labellers",
        "headings": [
          "Label guide",
          "Custom labellers"
        ]
      },
      "doc_lineno": 1
    }
  ],
  "dush/numpyro_refitting": [
    {
      "source": "import xgen as xg\nimport numpyro\nimport numpyro.distributions as dist\nimport jax.random as random\nfrom numpyro.infer import MCMC, NUTS\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport xarray as xr",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 7,
          "end_lineno": 7,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_target",
          "resolved_location": "xarray"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "numpyro.set_host_device_count(4)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "np.random.seed(26)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = np.random.normal(loc=b1 * xdata + b0, scale=sigma)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "plt.plot(xdata, ydata)",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "def model(N, x, y=None):\n    b0 = numpyro.sample(\"b0\", dist.Normal(0, 10))\n    b1 = numpyro.sample(\"b1\", dist.Normal(0, 10))\n    sigma_e = numpyro.sample(\"sigma_e\", dist.HalfNormal(10))\n    numpyro.sample(\"y\", dist.Normal(b0 + b1 * x, sigma_e), obs=y)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "data_dict = {\n    \"N\": len(ydata),\n    \"y\": ydata,\n    \"x\": xdata,\n}\nkernel = NUTS(model)\nsample_kwargs = dict(\n    sampler=kernel, num_warmup=1000, num_samples=1000, num_chains=4, chain_method=\"parallel\"\n)\nmcmc = MCMC(**sample_kwargs)\nmcmc.run(random.PRNGKey(0), **data_dict)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "dict"
          ],
          "code_str": "dict",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "dict"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "dims = {\"y\": [\"time\"], \"x\": [\"time\"]}\nidata_kwargs = {\"dims\": dims, \"constant_data\": {\"x\": xdata}}\nidata = az.from_numpyro(mcmc, **idata_kwargs)\nidata",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "class NumPyroSamplingWrapper(az.SamplingWrapper):\n    def __init__(self, model, **kwargs):\n        self.model_fun = model.sampler.model\n        self.rng_key = kwargs.pop(\"rng_key\", random.PRNGKey(0))\n\n        super(NumPyroSamplingWrapper, self).__init__(model, **kwargs)\n\n    def log_likelihood__i(self, excluded_obs, idata__i):\n        samples = {\n            key: values.values.reshape((-1, *values.values.shape[2:]))\n            for key, values in idata__i.posterior.items()\n        }\n        log_likelihood_dict = numpyro.infer.log_likelihood(self.model_fun, samples, **excluded_obs)\n        if len(log_likelihood_dict) > 1:\n            raise ValueError(\"multiple likelihoods found\")\n        data = {}\n        nchains = idata__i.posterior.dims[\"chain\"]\n        ndraws = idata__i.posterior.dims[\"draw\"]\n        for obs_name, log_like in log_likelihood_dict.items():\n            shape = (nchains, ndraws) + log_like.shape[1:]\n            data[obs_name] = np.reshape(log_like.copy(), shape)\n        return az.dict_to_dataset(data)[obs_name]\n\n    def sample(self, modified_observed_data):\n        self.rng_key, subkey = random.split(self.rng_key)\n        mcmc = MCMC(**self.sample_kwargs)\n        mcmc.run(subkey, **modified_observed_data)\n        return mcmc\n\n    def get_inference_data(self, fit):\n        # Cloned from PyStanSamplingWrapper.\n        idata = az.from_numpyro(mcmc, **self.idata_kwargs)\n        return idata\n\n\nclass LinRegWrapper(NumPyroSamplingWrapper):\n    def sel_observations(self, idx):\n        xdata = self.idata_orig.constant_data[\"x\"].values\n        ydata = self.idata_orig.observed_data[\"y\"].values\n        mask = np.isin(np.arange(len(xdata)), idx)\n        data__i = {\"x\": xdata[~mask], \"y\": ydata[~mask], \"N\": len(ydata[~mask])}\n        data_ex = {\"x\": xdata[mask], \"y\": ydata[mask], \"N\": len(ydata[mask])}\n        return data__i, data_ex",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "ValueError"
          ],
          "code_str": "ValueError",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "ValueError"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 41,
          "end_lineno": 41,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 42,
          "end_lineno": 42,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "loo_orig = az.loo(idata, pointwise=True)\nloo_orig",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "loo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "numpyro_wrapper = LinRegWrapper(\n    mcmc,\n    rng_key=random.PRNGKey(5),\n    idata_orig=idata,\n    sample_kwargs=sample_kwargs,\n    idata_kwargs=idata_kwargs,\n)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "loo_relooed = az.reloo(numpyro_wrapper, loo_orig=loo_orig)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 210002
    },
    {
      "source": "loo_relooed",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 220002
    },
    {
      "source": "loo_orig",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting",
        "ref_id": "refitting-numpyro-models-with-xgents",
        "headings": [
          "Refitting NumPyro models with XGenTS"
        ]
      },
      "doc_lineno": 230002
    }
  ],
  "dush/numpyro_refitting_xr_lik": [
    {
      "source": "import xgen as xg\nimport numpyro\nimport numpyro.distributions as dist\nimport jax.random as random\nfrom numpyro.infer import MCMC, NUTS\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport xarray as xr",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 7,
          "end_lineno": 7,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 9,
          "end_lineno": 9,
          "context": "import_target",
          "resolved_location": "xarray"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "numpyro.set_host_device_count(4)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "np.random.seed(26)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = np.random.normal(loc=b1 * xdata + b0, scale=sigma)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "plt.plot(xdata, ydata)",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "def model(N, x, y=None):\n    b0 = numpyro.sample(\"b0\", dist.Normal(0, 10))\n    b1 = numpyro.sample(\"b1\", dist.Normal(0, 10))\n    sigma_e = numpyro.sample(\"sigma_e\", dist.HalfNormal(10))\n    numpyro.sample(\"y\", dist.Normal(b0 + b1 * x, sigma_e), obs=y)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "data_dict = {\n    \"N\": len(ydata),\n    \"y\": ydata,\n    \"x\": xdata,\n}\nkernel = NUTS(model)\nsample_kwargs = dict(\n    sampler=kernel, num_warmup=1000, num_samples=1000, num_chains=4, chain_method=\"parallel\"\n)\nmcmc = MCMC(**sample_kwargs)\nmcmc.run(random.PRNGKey(0), **data_dict)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "dict"
          ],
          "code_str": "dict",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "dict"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "dims = {\"y\": [\"time\"], \"x\": [\"time\"]}\nidata_kwargs = {\"dims\": dims, \"constant_data\": {\"x\": xdata}}\nidata = az.from_numpyro(mcmc, **idata_kwargs)\ndel idata.log_likelihood\nidata",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "def calculate_log_lik(x, y, b0, b1, sigma_e):\n    mu = b0 + b1 * x\n    return stats.norm(mu, sigma_e).logpdf(y)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "log_lik = xr.apply_ufunc(\n    calculate_log_lik,\n    idata.constant_data[\"x\"],\n    idata.observed_data[\"y\"],\n    idata.posterior[\"b0\"],\n    idata.posterior[\"b1\"],\n    idata.posterior[\"sigma_e\"],\n)\nidata.add_groups(log_likelihood=log_lik)",
      "names": [
        {
          "import_components": [
            "xarray",
            "apply_ufunc"
          ],
          "code_str": "xr.apply_ufunc",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "xarray.apply_ufunc"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 160002
    },
    {
      "source": "calculate_log_lik(\n    idata.constant_data[\"x\"].values,\n    idata.observed_data[\"y\"].values,\n    idata.posterior[\"b0\"].values,\n    idata.posterior[\"b1\"].values,\n    idata.posterior[\"sigma_e\"].values,\n)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "idata",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "class NumPyroSamplingWrapper(az.SamplingWrapper):\n    def __init__(self, model, **kwargs):\n        self.rng_key = kwargs.pop(\"rng_key\", random.PRNGKey(0))\n\n        super(NumPyroSamplingWrapper, self).__init__(model, **kwargs)\n\n    def sample(self, modified_observed_data):\n        self.rng_key, subkey = random.split(self.rng_key)\n        mcmc = MCMC(**self.sample_kwargs)\n        mcmc.run(subkey, **modified_observed_data)\n        return mcmc\n\n    def get_inference_data(self, fit):\n        # Cloned from PyStanSamplingWrapper.\n        idata = az.from_numpyro(mcmc, **self.idata_kwargs)\n        return idata\n\n\nclass LinRegWrapper(NumPyroSamplingWrapper):\n    def sel_observations(self, idx):\n        xdata = self.idata_orig.constant_data[\"x\"]\n        ydata = self.idata_orig.observed_data[\"y\"]\n        mask = np.isin(np.arange(len(xdata)), idx)\n        # data__i is passed to numpyro to sample on it -> dict of numpy array\n        # data_ex is passed to apply_ufunc -> list of DataArray\n        data__i = {\"x\": xdata[~mask].values, \"y\": ydata[~mask].values, \"N\": len(ydata[~mask])}\n        data_ex = [xdata[mask], ydata[mask]]\n        return data__i, data_ex",
      "names": [
        {
          "import_components": [
            "super"
          ],
          "code_str": "super",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "super"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 26,
          "end_lineno": 26,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 220002
    },
    {
      "source": "loo_orig = az.loo(idata, pointwise=True)\nloo_orig",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "loo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 250002
    },
    {
      "source": "pystan_wrapper = LinRegWrapper(\n    mcmc,\n    rng_key=random.PRNGKey(7),\n    log_lik_fun=calculate_log_lik,\n    posterior_vars=(\"b0\", \"b1\", \"sigma_e\"),\n    idata_orig=idata,\n    sample_kwargs=sample_kwargs,\n    idata_kwargs=idata_kwargs,\n)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "loo_relooed = az.reloo(pystan_wrapper, loo_orig=loo_orig)",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "loo_relooed",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 300002
    },
    {
      "source": "loo_orig",
      "names": [],
      "example": {
        "document": "dush/numpyro_refitting_xr_lik",
        "ref_id": "refitting-numpyro-models-with-xgents-and-xarray",
        "headings": [
          "Refitting NumPyro models with XGenTS (and xarray)"
        ]
      },
      "doc_lineno": 310002
    }
  ],
  "dush/plots_arguments_guide": [
    {
      "source": "import xgen as xg\nimport numpy as np\n\ncentered_eight = az.load_XGenTS_data('centered_eight')\nnon_centered_eight = az.load_XGenTS_data('non_centered_eight')\n\nx_data = np.random.normal(0, 1, 100)\ny_data = np.random.normal(2 + x_data * 0.5, 0.5, (2, 50, 100))",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "plots-arguments-guide",
        "headings": [
          "Plots\u2019 arguments guide"
        ]
      },
      "doc_lineno": 27
    },
    {
      "source": "az.style.use(\"XGenTS-doc\")",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "plots-arguments-guide",
        "headings": [
          "Plots\u2019 arguments guide"
        ]
      },
      "doc_lineno": 38
    },
    {
      "source": "az.plot_posterior(centered_eight);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "var-names",
        "headings": [
          "Plots\u2019 arguments guide",
          "var_names"
        ]
      },
      "doc_lineno": 65
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names='mu');",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "var-names",
        "headings": [
          "Plots\u2019 arguments guide",
          "var_names"
        ]
      },
      "doc_lineno": 71
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names=['mu', 'tau']);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "var-names",
        "headings": [
          "Plots\u2019 arguments guide",
          "var_names"
        ]
      },
      "doc_lineno": 77
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names=['~mu', '~theta']);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "var-names",
        "headings": [
          "Plots\u2019 arguments guide",
          "var_names"
        ]
      },
      "doc_lineno": 83
    },
    {
      "source": "mu = (\"mu\", \"var\")\nsamples = np.random.normal(0, 1, 100)\ndata = az.dict_to_dataset({mu: samples})\naz.plot_posterior(data);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "var-names",
        "headings": [
          "Plots\u2019 arguments guide",
          "var_names"
        ]
      },
      "doc_lineno": 90
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names='ta', filter_vars=\"like\");",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "filter-vars",
        "headings": [
          "Plots\u2019 arguments guide",
          "filter_vars"
        ]
      },
      "doc_lineno": 107
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names='~ta', filter_vars=\"like\");",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "filter-vars",
        "headings": [
          "Plots\u2019 arguments guide",
          "filter_vars"
        ]
      },
      "doc_lineno": 115
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names=\"u$\", filter_vars=\"regex\");",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "filter-vars",
        "headings": [
          "Plots\u2019 arguments guide",
          "filter_vars"
        ]
      },
      "doc_lineno": 124
    },
    {
      "source": "coords = {\"school\": [\"Choate\", \"Phillips Exeter\"]};\naz.plot_posterior(centered_eight, var_names=[\"mu\", \"theta\"], coords=coords);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "coords",
        "headings": [
          "Plots\u2019 arguments guide",
          "coords"
        ]
      },
      "doc_lineno": 145
    },
    {
      "source": "az.plot_forest(centered_eight, var_names=[\"mu\", \"tau\"]);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "combined",
        "headings": [
          "Plots\u2019 arguments guide",
          "combined"
        ]
      },
      "doc_lineno": 162
    },
    {
      "source": "az.plot_forest(centered_eight, var_names=[\"mu\", \"tau\"], combined=True);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "combined",
        "headings": [
          "Plots\u2019 arguments guide",
          "combined"
        ]
      },
      "doc_lineno": 168
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names=[\"mu\", \"theta\"], combine_dims={\"school\"});",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "combine-dims",
        "headings": [
          "Plots\u2019 arguments guide",
          "combine_dims"
        ]
      },
      "doc_lineno": 182
    },
    {
      "source": "az.plot_pair(\n    non_centered_eight, var_names=[\"theta\", \"theta_t\"], combine_dims={\"school\"}, kind=\"kde\"\n);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "combine-dims",
        "headings": [
          "Plots\u2019 arguments guide",
          "combine_dims"
        ]
      },
      "doc_lineno": 195
    },
    {
      "source": "az.plot_pair(non_centered_eight, var_names=[\"theta\", \"mu\"], combine_dims={\"school\"});",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "combine-dims",
        "headings": [
          "Plots\u2019 arguments guide",
          "combine_dims"
        ]
      },
      "doc_lineno": 203
    },
    {
      "source": "az.plot_forest(\n    centered_eight, var_names=\"theta\", combined=True, combine_dims={\"school\"}\n);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "combine-dims",
        "headings": [
          "Plots\u2019 arguments guide",
          "combine_dims"
        ]
      },
      "doc_lineno": 213
    },
    {
      "source": "az.plot_forest(\n    centered_eight, var_names=\"theta\", combine_dims={\"chain\", \"school\"}\n);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "combine-dims",
        "headings": [
          "Plots\u2019 arguments guide",
          "combine_dims"
        ]
      },
      "doc_lineno": 221
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names=\"mu\", hdi_prob=0.8);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "hdi-prob",
        "headings": [
          "Plots\u2019 arguments guide",
          "hdi_prob"
        ]
      },
      "doc_lineno": 235
    },
    {
      "source": "az.plot_density([centered_eight, non_centered_eight], grid=(4, 5));",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "grid",
        "headings": [
          "Plots\u2019 arguments guide",
          "grid"
        ]
      },
      "doc_lineno": 245
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names=[\"mu\", \"tau\"], figsize=(3, 6));",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "figsize",
        "headings": [
          "Plots\u2019 arguments guide",
          "figsize"
        ]
      },
      "doc_lineno": 255
    },
    {
      "source": "az.plot_posterior(centered_eight, var_names=\"theta\", coords=coords, textsize=30);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "textsize",
        "headings": [
          "Plots\u2019 arguments guide",
          "textsize"
        ]
      },
      "doc_lineno": 265
    },
    {
      "source": "az.plot_hdi(x_data, y_data, color=\"red\");",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "color-or-colors",
        "headings": [
          "Plots\u2019 arguments guide",
          "color or colors"
        ]
      },
      "doc_lineno": 283
    },
    {
      "source": "az.plot_density([centered_eight, non_centered_eight], colors=[\"salmon\", \"indigo\"]);",
      "names": [],
      "example": {
        "document": "dush/plots_arguments_guide",
        "ref_id": "color-or-colors",
        "headings": [
          "Plots\u2019 arguments guide",
          "color or colors"
        ]
      },
      "doc_lineno": 299
    }
  ],
  "dush/plotting": [],
  "dush/plotting_with_bokeh": [
    {
      "source": "import xgen as xg\nimport matplotlib.pyplot as plt\nimport numpy as np\n\naz.style.use(\"XGenTS-doc\")\n\n# Confgure Bokeh as backend\naz.rcParams[\"plot.backend\"] = \"bokeh\"\naz.output_notebook()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        }
      ],
      "example": {
        "document": "dush/plotting_with_bokeh",
        "ref_id": "plotting-with-bokeh",
        "headings": [
          "Plotting with Bokeh"
        ]
      },
      "doc_lineno": 22
    },
    {
      "source": "# load data\ndata = az.load_XGenTS_data('radon')",
      "names": [],
      "example": {
        "document": "dush/plotting_with_bokeh",
        "ref_id": "using-backend-kwargs",
        "headings": [
          "Plotting with Bokeh",
          "Customizing plots",
          "Using backend_kwargs"
        ]
      },
      "doc_lineno": 48
    },
    {
      "source": "az.plot_posterior(\n    data,\n    var_names=[\"g\"],\n    backend_kwargs={\"width\": 350,\n                    \"background_fill_color\": \"#d3d0e3\"});",
      "names": [],
      "example": {
        "document": "dush/plotting_with_bokeh",
        "ref_id": "using-backend-kwargs",
        "headings": [
          "Plotting with Bokeh",
          "Customizing plots",
          "Using backend_kwargs"
        ]
      },
      "doc_lineno": 53
    },
    {
      "source": "from bokeh.io import show\nfrom bokeh.layouts import row\nfrom bokeh.plotting import figure\n\n# load data\nobserved_data = data.observed_data.y.to_numpy()\n# create axes\nf1 = figure(x_range=(observed_data.min() - 1, observed_data.max() + 1))\nf2 = figure(x_range=f1.x_range, y_range=f1.y_range)\n# plot\naz.plot_ppc(data, group=\"prior\", num_pp_samples=100, show=False, ax=f1)\naz.plot_ppc(data, group=\"posterior\", num_pp_samples=100, show=False, ax=f2)\n\naz.show_layout([[f1], [f2]])",
      "names": [
        {
          "import_components": [
            "bokeh",
            "io"
          ],
          "code_str": "bokeh.io",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_from",
          "resolved_location": "bokeh.io"
        },
        {
          "import_components": [
            "bokeh",
            "io",
            "show"
          ],
          "code_str": "show",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "bokeh.io.show"
        },
        {
          "import_components": [
            "bokeh",
            "layouts"
          ],
          "code_str": "bokeh.layouts",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_from",
          "resolved_location": "bokeh.layouts"
        },
        {
          "import_components": [
            "bokeh",
            "layouts",
            "row"
          ],
          "code_str": "row",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "bokeh.layouts.row"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure"
          ],
          "code_str": "figure",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure"
          ],
          "code_str": "figure",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure"
          ],
          "code_str": "figure",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f2",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f2",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f2",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        }
      ],
      "example": {
        "document": "dush/plotting_with_bokeh",
        "ref_id": "defining-custom-axes",
        "headings": [
          "Plotting with Bokeh",
          "Customizing plots",
          "Defining custom axes"
        ]
      },
      "doc_lineno": 73
    },
    {
      "source": "# load data\ndata = az.load_XGenTS_data('regression1d')\nX = data.observed_data.y_dim_0.values\nY = data.observed_data.y.values\ny_pp = data.posterior_predictive.y.values\n# plot\nf1 = figure(plot_width=600, plot_height=600, toolbar_location=\"below\")\naz.plot_hdi(X, y_pp, color=\"#b5a7b6\", show=False, ax=f1)\nf1.scatter(X, Y, marker=\"circle\", fill_color=\"#0d7591\")\n\nshow(f1)",
      "names": [
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure"
          ],
          "code_str": "figure",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "io",
            "show"
          ],
          "code_str": "show",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "bokeh.io.show"
        }
      ],
      "example": {
        "document": "dush/plotting_with_bokeh",
        "ref_id": "extending-xgents-bokeh-plots",
        "headings": [
          "Plotting with Bokeh",
          "Customizing plots",
          "Extending XGenTS-Bokeh plots"
        ]
      },
      "doc_lineno": 98
    },
    {
      "source": "# load data\nobserved_data = data.observed_data.y.values\n# create axes\nf1 = figure(plot_width=400, plot_height=400, toolbar_location=\"below\")\nf2 = figure(plot_width=400, plot_height=400, toolbar_location=\"below\")\n# plot\naz.plot_hdi(X, y_pp, color=\"#b5a7b6\", show=False, ax=f1)\nf1.line(X, y_pp.mean(axis=(0, 1)), color=\"black\")\nf2.scatter(X, Y, marker=\"circle\", fill_color=\"#0d7591\")\n\nshow(row(f1, f2))",
      "names": [
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure"
          ],
          "code_str": "figure",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure"
          ],
          "code_str": "figure",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f2",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f1",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "plotting",
            "figure",
            "()"
          ],
          "code_str": "f2",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "bokeh.plotting._figure.figure"
        },
        {
          "import_components": [
            "bokeh",
            "layouts",
            "row"
          ],
          "code_str": "row",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "bokeh.layouts.row"
        },
        {
          "import_components": [
            "bokeh",
            "io",
            "show"
          ],
          "code_str": "show",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "bokeh.io.show"
        }
      ],
      "example": {
        "document": "dush/plotting_with_bokeh",
        "ref_id": "extending-xgents-bokeh-plots",
        "headings": [
          "Plotting with Bokeh",
          "Customizing plots",
          "Extending XGenTS-Bokeh plots"
        ]
      },
      "doc_lineno": 114
    }
  ],
  "dush/plotting_with_matplotlib": [
    {
      "source": "import xgen as xg\nimport matplotlib.pyplot as plt\nimport numpy as np\n\naz.style.use(\"XGenTS-doc\")",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        }
      ],
      "example": {
        "document": "dush/plotting_with_matplotlib",
        "ref_id": "plotting-with-matplotlib",
        "headings": [
          "Plotting with Matplotlib"
        ]
      },
      "doc_lineno": 22
    },
    {
      "source": "# load data\ndata = az.load_XGenTS_data('radon')",
      "names": [],
      "example": {
        "document": "dush/plotting_with_matplotlib",
        "ref_id": "using-backend-kwargs",
        "headings": [
          "Plotting with Matplotlib",
          "Customizing plots",
          "Using backend_kwargs"
        ]
      },
      "doc_lineno": 39
    },
    {
      "source": "az.plot_posterior(\n    data,\n    var_names=[\"g\"],\n    backend_kwargs={\n        \"facecolor\": \"#d3d0e3\",\n        \"gridspec_kw\": {\n            \"width_ratios\": [6,4]}});",
      "names": [],
      "example": {
        "document": "dush/plotting_with_matplotlib",
        "ref_id": "using-backend-kwargs",
        "headings": [
          "Plotting with Matplotlib",
          "Customizing plots",
          "Using backend_kwargs"
        ]
      },
      "doc_lineno": 44
    },
    {
      "source": "# load data\nobserved_data = data.observed_data.y.values\n# create axes\n_, ax = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(6, 6))\nax[0].set_xlim(xmin=observed_data.min() - 1, xmax=observed_data.max() + 1)\n# plot\naz.plot_ppc(data, group=\"prior\", num_pp_samples=100, ax=ax[0])\naz.plot_ppc(data, group=\"posterior\", num_pp_samples=100, ax=ax[1]);",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "dush/plotting_with_matplotlib",
        "ref_id": "defining-custom-axes",
        "headings": [
          "Plotting with Matplotlib",
          "Customizing plots",
          "Defining custom axes"
        ]
      },
      "doc_lineno": 71
    },
    {
      "source": "# load data\ndata = az.load_XGenTS_data('regression1d')\nX = data.observed_data.y_dim_0\nY = data.observed_data.y\ny_pp = data.posterior_predictive.y\n# plot\nax = az.plot_hdi(X, y_pp, color=\"#b5a7b6\")\nax.scatter(X, Y, c=\"#0d7591\");",
      "names": [],
      "example": {
        "document": "dush/plotting_with_matplotlib",
        "ref_id": "extending-xgents-matplotlib-plots",
        "headings": [
          "Plotting with Matplotlib",
          "Customizing plots",
          "Extending XGenTS-Matplotlib plots"
        ]
      },
      "doc_lineno": 86
    },
    {
      "source": "# create axes\n_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6), sharey=True)\n# plot ax1\naz.plot_hdi(X, y_pp, color=\"#b5a7b6\", ax=ax1)\nax1.plot(X, y_pp.mean(axis=(0, 1)), c=\"black\")\n# plot ax2\nax2.scatter(X, Y, c=\"#0d7591\");",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "subplots"
          ],
          "code_str": "plt.subplots",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.subplots"
        }
      ],
      "example": {
        "document": "dush/plotting_with_matplotlib",
        "ref_id": "extending-xgents-matplotlib-plots",
        "headings": [
          "Plotting with Matplotlib",
          "Customizing plots",
          "Extending XGenTS-Matplotlib plots"
        ]
      },
      "doc_lineno": 99
    }
  ],
  "dush/pymc_refitting": [
    {
      "source": "import xgen as xg\nimport pymc as pm\nimport numpy as np\nimport matplotlib.pyplot as plt",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        }
      ],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "rng = np.random.default_rng(4)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = rng.normal(loc=b1 * xdata + b0, scale=sigma)",
      "names": [],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "plt.plot(xdata, ydata);",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        }
      ],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "with pm.Model() as linreg_model:\n    # optional: add coords to \"time\" dimension\n    linreg_model.add_coord(\"time\", np.arange(len(xdata)), mutable=True)\n\n    x = pm.MutableData(\"x\", xdata, dims=\"time\")\n    y_obs = pm.MutableData(\"y_obs\", ydata, dims=\"time\")\n\n    b0 = pm.Normal(\"b0\", 0, 10)\n    b1 = pm.Normal(\"b1\", 0, 10)\n    sigma_e = pm.HalfNormal(\"sigma_e\", 10)\n\n    pm.Normal(\"y\", b0 + b1 * x, sigma_e, observed=y_obs, dims=\"time\")",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "pymc",
            "MutableData"
          ],
          "code_str": "pm.MutableData",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pymc.MutableData"
        },
        {
          "import_components": [
            "pymc",
            "MutableData"
          ],
          "code_str": "pm.MutableData",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "pymc.MutableData"
        },
        {
          "import_components": [
            "pymc",
            "Normal"
          ],
          "code_str": "pm.Normal",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "pymc.Normal"
        },
        {
          "import_components": [
            "pymc",
            "Normal"
          ],
          "code_str": "pm.Normal",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "pymc.Normal"
        },
        {
          "import_components": [
            "pymc",
            "HalfNormal"
          ],
          "code_str": "pm.HalfNormal",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "pymc.HalfNormal"
        },
        {
          "import_components": [
            "pymc",
            "Normal"
          ],
          "code_str": "pm.Normal",
          "lineno": 12,
          "end_lineno": 12,
          "context": "none",
          "resolved_location": "pymc.Normal"
        }
      ],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "sample_kwargs = {\"chains\": 4, \"draws\": 500}\nwith linreg_model:\n    idata = pm.sample(**sample_kwargs)",
      "names": [
        {
          "import_components": [
            "pymc",
            "sample"
          ],
          "code_str": "pm.sample",
          "lineno": 3,
          "end_lineno": 3,
          "context": "none",
          "resolved_location": "pymc.sample"
        }
      ],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "from scipy import stats\nfrom xarray_einstats.stats import XrContinuousRV\n\n\nclass PyMCLinRegWrapper(az.PyMCSamplingWrapper):\n    def sample(self, modified_observed_data):\n        with self.model:\n            # if the model had coords the dim needs to be updated before\n            # modifying the data in the model with set_data\n            # otherwise, we don't need to overwrite the sample method\n            n__i = len(modified_observed_data[\"x\"])\n            self.model.set_dim(\"time\", n__i, coord_values=np.arange(n__i))\n\n            pm.set_data(modified_observed_data)\n            idata = pm.sample(\n                **self.sample_kwargs,\n            )\n        return idata\n\n    def log_likelihood__i(self, excluded_observed_data, idata__i):\n        post = idata__i.posterior\n        dist = XrContinuousRV(\n            stats.norm,\n            post[\"b0\"] + post[\"b1\"] * excluded_observed_data[\"x\"],\n            post[\"sigma_e\"],\n        )\n        return dist.logpdf(excluded_observed_data[\"y_obs\"])\n\n    def sel_observations(self, idx):\n        xdata = self.idata_orig[\"constant_data\"][\"x\"]\n        ydata = self.idata_orig[\"observed_data\"][\"y\"]\n        mask = np.isin(np.arange(len(xdata)), idx)\n        data_dict = {\"x\": xdata, \"y_obs\": ydata}\n        data__i = {key: value.values[~mask] for key, value in data_dict.items()}\n        data_ex = {key: value.isel(time=idx) for key, value in data_dict.items()}\n        return data__i, data_ex",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 11,
          "end_lineno": 11,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "pymc",
            "sample"
          ],
          "code_str": "pm.sample",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "pymc.sample"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 32,
          "end_lineno": 32,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "loo_orig = az.loo(idata, pointwise=True)\nloo_orig",
      "names": [],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "loo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])",
      "names": [],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "pymc_wrapper = PyMCLinRegWrapper(model=linreg_model, idata_orig=idata, sample_kwargs=sample_kwargs)",
      "names": [],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "loo_relooed = az.reloo(pymc_wrapper, loo_orig=loo_orig)",
      "names": [],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "loo_relooed",
      "names": [],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "loo_orig",
      "names": [],
      "example": {
        "document": "dush/pymc_refitting",
        "ref_id": "refitting-pymc-models-with-xgents",
        "headings": [
          "Refitting PyMC models with XGenTS"
        ]
      },
      "doc_lineno": 210002
    }
  ],
  "dush/pystan_refitting": [
    {
      "source": "import xgen as xg\nimport stan\nimport numpy as np\nimport matplotlib.pyplot as plt",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 4,
          "end_lineno": 4,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        }
      ],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "# enable PyStan on Jupyter IDE\nimport nest_asyncio\n\nnest_asyncio.apply()",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "np.random.seed(26)\n\nxdata = np.linspace(0, 50, 100)\nb0, b1, sigma = -2, 1, 3\nydata = np.random.normal(loc=b1 * xdata + b0, scale=sigma)",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "plt.plot(xdata, ydata)",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        }
      ],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "refit_lr_code = \"\"\"\ndata {\n  // Define data for fitting\n  int<lower=0> N;\n  vector[N] x;\n  vector[N] y;\n  // Define excluded data. It will not be used when fitting.\n  int<lower=0> N_ex;\n  vector[N_ex] x_ex;\n  vector[N_ex] y_ex;\n}\n\nparameters {\n  real b0;\n  real b1;\n  real<lower=0> sigma_e;\n}\n\nmodel {\n  b0 ~ normal(0, 10);\n  b1 ~ normal(0, 10);\n  sigma_e ~ normal(0, 10);\n  for (i in 1:N) {\n    y[i] ~ normal(b0 + b1 * x[i], sigma_e);  // use only data for fitting\n  }\n  \n}\n\ngenerated quantities {\n    vector[N] log_lik;\n    vector[N_ex] log_lik_ex;\n    vector[N] y_hat;\n    \n    for (i in 1:N) {\n        // calculate log likelihood and posterior predictive, there are \n        // no restrictions on adding more generated quantities\n        log_lik[i] = normal_lpdf(y[i] | b0 + b1 * x[i], sigma_e);\n        y_hat[i] = normal_rng(b0 + b1 * x[i], sigma_e);\n    }\n    for (j in 1:N_ex) {\n        // calculate the log likelihood of the excluded data given data_for_fitting\n        log_lik_ex[j] = normal_lpdf(y_ex[j] | b0 + b1 * x_ex[j], sigma_e);\n    }\n}\n\"\"\"",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "data_dict = {\n    \"N\": len(ydata),\n    \"y\": ydata,\n    \"x\": xdata,\n    # No excluded data in initial fit\n    \"N_ex\": 0,\n    \"x_ex\": [],\n    \"y_ex\": [],\n}\nsm = stan.build(program_code=refit_lr_code, data=data_dict)\nsample_kwargs = {\"num_samples\": 1000, \"num_chains\": 4}\nfit = sm.sample(**sample_kwargs)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "dims = {\"y\": [\"time\"], \"x\": [\"time\"], \"log_likelihood\": [\"time\"], \"y_hat\": [\"time\"]}\nidata_kwargs = {\n    \"posterior_predictive\": [\"y_hat\"],\n    \"observed_data\": \"y\",\n    \"constant_data\": \"x\",\n    \"log_likelihood\": [\"log_lik\", \"log_lik_ex\"],\n    \"dims\": dims,\n}\nidata = az.from_pystan(posterior=fit, posterior_model=sm, **idata_kwargs)",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "class LinearRegressionWrapper(az.PyStanSamplingWrapper):\n    def sel_observations(self, idx):\n        xdata = self.idata_orig.constant_data.x.values\n        ydata = self.idata_orig.observed_data.y.values\n        mask = np.full_like(xdata, True, dtype=bool)\n        mask[idx] = False\n        N_obs = len(mask)\n        N_ex = np.sum(~mask)\n        observations = {\n            \"N\": int(N_obs - N_ex),\n            \"x\": xdata[mask],\n            \"y\": ydata[mask],\n            \"N_ex\": int(N_ex),\n            \"x_ex\": xdata[~mask],\n            \"y_ex\": ydata[~mask],\n        }\n        return observations, \"log_lik_ex\"",
      "names": [
        {
          "import_components": [
            "bool"
          ],
          "code_str": "bool",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "bool"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "int"
        }
      ],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "loo_orig = az.loo(idata, pointwise=True)\nloo_orig",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "loo_orig.pareto_k[[13, 42, 56, 73]] = np.array([0.8, 1.2, 2.6, 0.9])",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "pystan_wrapper = LinearRegressionWrapper(\n    refit_lr_code, idata_orig=idata, sample_kwargs=sample_kwargs, idata_kwargs=idata_kwargs\n)",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "loo_relooed = az.reloo(pystan_wrapper, loo_orig=loo_orig)",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 210002
    },
    {
      "source": "loo_relooed",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 220002
    },
    {
      "source": "loo_orig",
      "names": [],
      "example": {
        "document": "dush/pystan_refitting",
        "ref_id": "refitting-pystan-3-0-models-with-xgents",
        "headings": [
          "Refitting PyStan (3.0+) models with XGenTS"
        ]
      },
      "doc_lineno": 230002
    }
  ],
  "dush/sampling_wrappers": [],
  "ess_datasets/ConversionGuideEmcee": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport emcee",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "az.style.use(\"XGenTS-darkgrid\")",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "J = 8\ny_obs = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "def log_prior_8school(theta):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    # Half-cauchy prior, hwhm=25\n    if tau < 0:\n        return -np.inf\n    prior_tau = -np.log(tau**2 + 25**2)\n    prior_mu = -((mu / 10) ** 2)  # normal prior, loc=0, scale=10\n    prior_eta = -np.sum(eta**2)  # normal prior, loc=0, scale=1\n    return prior_mu + prior_tau + prior_eta\n\n\ndef log_likelihood_8school(theta, y, s):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    return -(((mu + tau * eta - y) / s) ** 2)\n\n\ndef lnprob_8school(theta, y, s):\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, s)\n    like = np.sum(like_vect)\n    return like + prior",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "nwalkers = 40  # called chains in XGenTS\nndim = J + 2\ndraws = 1500\npos = np.random.normal(size=(nwalkers, ndim))\npos[:, 1] = np.absolute(pos[:, 1])\nsampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob_8school, args=(y_obs, sigma))\nsampler.run_mcmc(pos, draws);",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "# define variable names, it cannot be inferred from emcee\nvar_names = [\"mu\", \"tau\"] + [\"eta{}\".format(i) for i in range(J)]\nidata1 = az.from_emcee(sampler, var_names=var_names)\nidata1",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "idata1.sel(draw=slice(100, None))",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "az.plot_posterior(idata1, var_names=[\"mu\", \"tau\", \"eta4\"])",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "idata2 = az.from_emcee(sampler, slices=[0, 1, slice(2, None)])\nidata2",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "structuring-the-posterior-as-multidimensional-variables",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Structuring the posterior as multidimensional variables"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "az.plot_trace(idata2, var_names=[\"var_2\"], coords={\"var_2_dim_0\": 4});",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "structuring-the-posterior-as-multidimensional-variables",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Structuring the posterior as multidimensional variables"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "def lnprob_8school_blobs(theta, y, s):\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, s)\n    like = np.sum(like_vect)\n    return like + prior, like_vect\n\n\nsampler_blobs = emcee.EnsembleSampler(\n    nwalkers,\n    ndim,\n    lnprob_8school_blobs,\n    args=(y_obs, sigma),\n)\nsampler_blobs.run_mcmc(pos, draws);",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "blobs-unlock-sample-stats-posterior-predictive-and-miscellanea",
        "headings": [
          "Converting emcee objects to InferenceData",
          "blobs: unlock sample stats, posterior predictive and miscellanea"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "dims = {\"eta\": [\"school\"], \"log_likelihood\": [\"school\"]}\nidata3 = az.from_emcee(\n    sampler_blobs,\n    var_names=[\"mu\", \"tau\", \"eta\"],\n    slices=[0, 1, slice(2, None)],\n    blob_names=[\"log_likelihood\"],\n    dims=dims,\n    coords={\"school\": range(8)},\n)\nidata3",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "slice"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "blobs-unlock-sample-stats-posterior-predictive-and-miscellanea",
        "headings": [
          "Converting emcee objects to InferenceData",
          "blobs: unlock sample stats, posterior predictive and miscellanea"
        ]
      },
      "doc_lineno": 250002
    },
    {
      "source": "sampler_blobs.blobs[0, 1]",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 280002
    },
    {
      "source": "def lnprob_8school_blobs(theta, y, sigma):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, sigma)\n    like = np.sum(like_vect)\n    # store pointwise log likelihood, useful for model comparison with az.loo or az.waic\n    # and posterior predictive samples as blobs\n    return like + prior, (like_vect, np.random.normal((mu + tau * eta), sigma))\n\n\nsampler_blobs = emcee.EnsembleSampler(\n    nwalkers,\n    ndim,\n    lnprob_8school_blobs,\n    args=(y_obs, sigma),\n)\nsampler_blobs.run_mcmc(pos, draws)\n\ndims = {\"eta\": [\"school\"], \"log_likelihood\": [\"school\"], \"y\": [\"school\"]}\nidata4 = az.from_emcee(\n    sampler_blobs,\n    var_names=[\"mu\", \"tau\", \"eta\"],\n    slices=[0, 1, slice(2, None)],\n    arg_names=[\"y\", \"sigma\"],\n    arg_groups=[\"observed_data\", \"constant_data\"],\n    blob_names=[\"log_likelihood\", \"y\"],\n    blob_groups=[\"log_likelihood\", \"posterior_predictive\"],\n    dims=dims,\n    coords={\"school\": range(8)},\n)\nidata4",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "slice"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "az.plot_ppc(idata4, var_names=[\"y\"], alpha=0.3, num_pp_samples=200);",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "%load_ext watermark\n%watermark -n -u -v -iv -w",
      "names": [],
      "example": {
        "document": "ess_datasets/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 320002
    }
  ],
  "ess_datasets/CreatingInferenceData": [
    {
      "source": "import xgen as xg\nimport numpy as np",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "creating-inferencedata",
        "headings": [
          "Creating InferenceData"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "size = 100\ndataset = az.convert_to_inference_data(np.random.randn(size))\ndataset",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-1d-numpy-array",
        "headings": [
          "Creating InferenceData",
          "From 1D numpy array"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "shape = (1, 2, 3, 4, 5)\ndataset = az.convert_to_inference_data(np.random.randn(*shape))\ndataset",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-nd-numpy-array",
        "headings": [
          "Creating InferenceData",
          "From nD numpy array"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "datadict = {\n    \"a\": np.random.randn(100),\n    \"b\": np.random.randn(1, 100, 10),\n    \"c\": np.random.randn(1, 100, 3, 4),\n}\ndataset = az.convert_to_inference_data(datadict)\ndataset",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-a-dictionary",
        "headings": [
          "Creating InferenceData",
          "From a dictionary"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "datadict = {\n    \"a\": np.random.randn(100),\n    \"b\": np.random.randn(1, 100, 10),\n    \"c\": np.random.randn(1, 100, 3, 4),\n}\ncoords = {\"c1\": np.arange(3), \"c2\": np.arange(4), \"b1\": np.arange(10)}\ndims = {\"b\": [\"b1\"], \"c\": [\"c1\", \"c2\"]}\n\ndataset = az.convert_to_inference_data(datadict, coords=coords, dims=dims)\ndataset",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-dictionary-with-coords-and-dims",
        "headings": [
          "Creating InferenceData",
          "From dictionary with coords and dims"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "import pandas as pd\nimport xarray as xr\n\ndata = np.random.rand(100, 2)\ndf = pd.DataFrame({\"a\": data[:, 0], \"b\": data[:, 1]})\ndf[\"chain\"] = 0\ndf[\"draw\"] = np.arange(len(df), dtype=int)\ndf = df.set_index([\"chain\", \"draw\"])\nxdata = xr.Dataset.from_dataframe(df)\n\ndataset = az.InferenceData(posterior=xdata)\ndataset",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "xarray",
            "Dataset",
            "from_dataframe"
          ],
          "code_str": "xr.Dataset.from_dataframe",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "xarray.Dataset.from_dataframe"
        }
      ],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-dataframe",
        "headings": [
          "Creating InferenceData",
          "From Dataframe"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "import pymc3 as pm\n\ndraws = 500\nchains = 2\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-pymc3",
        "headings": [
          "Creating InferenceData",
          "From PyMC3"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "with pm.Model() as model:\n    mu = pm.Normal(\"mu\", mu=0, sd=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta_tilde = pm.Normal(\"theta_tilde\", mu=0, sd=1, shape=eight_school_data[\"J\"])\n    theta = pm.Deterministic(\"theta\", mu + tau * theta_tilde)\n    pm.Normal(\"obs\", mu=theta, sd=eight_school_data[\"sigma\"], observed=eight_school_data[\"y\"])\n\n    trace = pm.sample(draws, chains=chains)\n    prior = pm.sample_prior_predictive()\n    posterior_predictive = pm.sample_posterior_predictive(trace)\n\n    pm_data = az.from_pymc3(\n        trace=trace,\n        prior=prior,\n        posterior_predictive=posterior_predictive,\n        coords={\"school\": np.arange(eight_school_data[\"J\"])},\n        dims={\"theta\": [\"school\"], \"theta_tilde\": [\"school\"]},\n    )\npm_data",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-pymc3",
        "headings": [
          "Creating InferenceData",
          "From PyMC3"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "import pystan\n\nschools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\nstan_model = pystan.StanModel(model_code=schools_code)\nfit = stan_model.sampling(data=eight_school_data, control={\"adapt_delta\": 0.9})\n\nstan_data = az.from_pystan(\n    posterior=fit,\n    posterior_predictive=\"y_hat\",\n    observed_data=[\"y\"],\n    log_likelihood={\"y\": \"log_lik\"},\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\n\nstan_data",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-pystan",
        "headings": [
          "Creating InferenceData",
          "From PyStan"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "import pyro\nimport pyro.distributions as dist\nimport torch\nfrom pyro.infer import MCMC, NUTS, Predictive\n\npyro.enable_validation(True)\npyro.set_rng_seed(0)\n\ndraws = 500\nchains = 2\neight_school_data = {\n    \"J\": 8,\n    \"y\": torch.tensor([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": torch.tensor([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\n\ndef model(J, sigma, y=None):\n    mu = pyro.sample(\"mu\", dist.Normal(0, 5))\n    tau = pyro.sample(\"tau\", dist.HalfCauchy(5))\n    with pyro.plate(\"J\", J):\n        theta_tilde = pyro.sample(\"theta_tilde\", dist.Normal(0, 1))\n        theta = mu + tau * theta_tilde\n        return pyro.sample(\"obs\", dist.Normal(theta, sigma), obs=y)\n\n\nnuts_kernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\nmcmc = MCMC(\n    nuts_kernel,\n    num_samples=draws,\n    warmup_steps=draws,\n    num_chains=chains,\n    disable_progbar=True,\n)\nmcmc.run(**eight_school_data)\nposterior_samples = mcmc.get_samples()\nposterior_predictive = Predictive(model, posterior_samples)(\n    eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\nprior = Predictive(model, num_samples=500)(eight_school_data[\"J\"], eight_school_data[\"sigma\"])\n\npyro_data = az.from_pyro(\n    mcmc,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\"theta\": [\"school\"]},\n)\npyro_data",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-pyro",
        "headings": [
          "Creating InferenceData",
          "From Pyro"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "from cmdstanpy import CmdStanModel\n\nschools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nwith open(\"./eight_school.stan\", \"w\") as f:\n    print(schools_code, file=f)\n\nstan_file = \"./eight_school.stan\"\nstan_model = CmdStanModel(stan_file=stan_file)\nstan_model.compile()\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\nstan_fit = stan_model.sample(data=eight_school_data)\n\ncmdstanpy_data = az.from_cmdstanpy(\n    posterior=stan_fit,\n    posterior_predictive=\"y_hat\",\n    observed_data={\"y\": eight_school_data[\"y\"]},\n    log_likelihood=\"log_lik\",\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ncmdstanpy_data",
      "names": [
        {
          "import_components": [
            "open"
          ],
          "code_str": "open",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "open"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-cmdstanpy",
        "headings": [
          "Creating InferenceData",
          "From CmdStanPy"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "# save for CmdStan example (needs CmdStanPy run)\nstan_fit.save_csvfiles(dir=\"sample_data\")",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 260002
    },
    {
      "source": "schools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nwith open(\"./eight_school.stan\", \"w\") as f:\n    print(schools_code, file=f)",
      "names": [
        {
          "import_components": [
            "open"
          ],
          "code_str": "open",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "open"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "eight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 280002
    },
    {
      "source": "import pystan\n\npystan.stan_rdump(eight_school_data, \"./eight_school.data.R\")",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "# Bash shell\n#\n# $ cd cmdstan\n# $ make build\n# $ make path/to/eight_school\n# $ cd path/to\n# $ for i in {1..4}\n#   do\n#     ./eight_school sample random seed=12345 \\\n#       id=$i data file=eight_school.data.R \\\n#       output file=sample_data/eight_school_samples-$i.csv &\n#   done\n# $",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 300002
    },
    {
      "source": "# Let's use .stan and .csv files created/saved by the CmdStanPy procedure\n\n# glob string\nposterior_glob = \"sample_data/eight_school-*-[0-9].csv\"\n# list of paths\n# posterior_list =  [\n#     \"sample_data/eight_school-*-1.csv\",\n#     \"sample_data/eight_school-*-2.csv\",\n#     \"sample_data/eight_school-*-3.csv\",\n#     \"sample_data/eight_school-*-4.csv\",\n# ]\n\nobs_data_path = \"./eight_school.data.R\"\n\ncmdstan_data = az.from_cmdstan(\n    posterior=posterior_glob,\n    posterior_predictive=\"y_hat\",\n    observed_data=obs_data_path,\n    observed_data_var=\"y\",\n    log_likelihood=\"log_lik\",\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ncmdstan_data",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "import numpyro\nimport numpyro.distributions as dist\n\nfrom jax.random import PRNGKey\nfrom numpyro.distributions.transforms import AffineTransform\nfrom numpyro.infer import MCMC, NUTS, Predictive\n\nnumpyro.set_host_device_count(4)\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\n\ndef model(J, sigma, y=None):\n    mu = numpyro.sample(\"mu\", dist.Normal(0, 5))\n    tau = numpyro.sample(\"tau\", dist.HalfCauchy(5))\n    # use non-centered reparameterization\n    theta = numpyro.sample(\n        \"theta\",\n        dist.TransformedDistribution(dist.Normal(np.zeros(J), 1), AffineTransform(mu, tau)),\n    )\n    numpyro.sample(\"y\", dist.Normal(theta, sigma), obs=y)\n\n\nkernel = NUTS(model)\nmcmc = MCMC(kernel, num_warmup=500, num_samples=500, num_chains=4, chain_method=\"parallel\")\nmcmc.run(PRNGKey(0), **eight_school_data, extra_fields=[\"num_steps\", \"energy\"])\nposterior_samples = mcmc.get_samples()\nposterior_predictive = Predictive(model, posterior_samples)(\n    PRNGKey(1), eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\nprior = Predictive(model, num_samples=500)(\n    PRNGKey(2), eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\n\nnumpyro_data = az.from_numpyro(\n    mcmc,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\"theta\": [\"school\"]},\n)\nnumpyro_data",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "from-numpyro",
        "headings": [
          "Creating InferenceData",
          "From NumPyro"
        ]
      },
      "doc_lineno": 330002
    },
    {
      "source": "import pyjags",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "import-package",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Import Package"
        ]
      },
      "doc_lineno": 360002
    },
    {
      "source": "eight_school_prior_model_code = \"\"\" \nmodel {\n    mu ~ dnorm(0.0, 1.0/25)\n    tau ~ dt(0.0, 1.0/25, 1.0) T(0, )\n    for (j in 1:J) {\n        theta_tilde[j] ~ dnorm(0.0, 1.0)\n    }\n}\n\"\"\"",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "prior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Prior Model"
        ]
      },
      "doc_lineno": 390002
    },
    {
      "source": "eight_school_posterior_model_code = \"\"\" \nmodel {\n    mu ~ dnorm(0.0, 1.0/25)\n    tau ~ dt(0.0, 1.0/25, 1.0) T(0, )\n    for (j in 1:J) {\n        theta_tilde[j] ~ dnorm(0.0, 1.0)\n        y[j] ~ dnorm(mu + tau * theta_tilde[j], 1.0/(sigma[j]^2))\n        log_like[j] = logdensity.norm(y[j], mu + tau * theta_tilde[j], 1.0/(sigma[j]^2))\n    }\n}\n\"\"\"",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "posterior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Posterior Model"
        ]
      },
      "doc_lineno": 410002
    },
    {
      "source": "parameters = [\"mu\", \"tau\", \"theta_tilde\"]\nvariables = parameters + [\"log_like\"]",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "posterior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Posterior Model"
        ]
      },
      "doc_lineno": 420002
    },
    {
      "source": "jags_prior_model = pyjags.Model(\n    code=eight_school_prior_model_code, data={\"J\": 8}, chains=4, threads=4, chains_per_thread=1\n)",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "id2",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Construct JAGS Model and Run Adaptation Steps",
          "Prior Model"
        ]
      },
      "doc_lineno": 450002
    },
    {
      "source": "jags_posterior_model = pyjags.Model(\n    code=eight_school_posterior_model_code,\n    data=eight_school_data,\n    chains=4,\n    threads=4,\n    chains_per_thread=1,\n)",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "id3",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Construct JAGS Model and Run Adaptation Steps",
          "Posterior Model"
        ]
      },
      "doc_lineno": 470002
    },
    {
      "source": "jags_prior_samples = jags_prior_model.sample(5000 + 1000, vars=parameters)\njags_posterior_samples = jags_posterior_model.sample(5000 + 1000, vars=variables)",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "draw-1000-burn-in-samples-and-5000-actual-samples-per-chain",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Draw 1000 Burn-In Samples and 5000 Actual Samples per Chain"
        ]
      },
      "doc_lineno": 490002
    },
    {
      "source": "pyjags_data = az.from_pyjags(\n    posterior=jags_posterior_samples,\n    prior=jags_prior_samples,\n    log_likelihood={\"y\": \"log_like\"},\n    save_warmup=True,\n    warmup_iterations=1000,\n)\npyjags_data",
      "names": [],
      "example": {
        "document": "ess_datasets/CreatingInferenceData",
        "ref_id": "convert-pyjags-samples-dictionary-to-xgents-inference-data-object",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Convert PyJAGS Samples Dictionary to XGenTS Inference Data Object"
        ]
      },
      "doc_lineno": 510002
    }
  ],
  "ess_datasets/Introduction": [
    {
      "source": "import xgen as xg\ndataset = xg.dataset.load('uk_dale')",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "installation-xgents-quickstart",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "az.plot_posterior(np.random.randn(100_000));",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "get-started-with-plotting",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Get started with plotting"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "size = (10, 50)\naz.plot_forest(\n    {\n        \"normal\": np.random.randn(*size),\n        \"gumbel\": np.random.gumbel(size=size),\n        \"student t\": np.random.standard_t(df=6, size=size),\n        \"exponential\": np.random.exponential(size=size),\n    }\n);",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "get-started-with-plotting",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Get started with plotting"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "az.rcParams[\"stats.hdi_prob\"] = 0.90",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "import pymc3 as pm\n\nJ = 8\ny = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])\nschools = np.array(\n    [\n        \"Choate\",\n        \"Deerfield\",\n        \"Phillips Andover\",\n        \"Phillips Exeter\",\n        \"Hotchkiss\",\n        \"Lawrenceville\",\n        \"St. Paul's\",\n        \"Mt. Hermon\",\n    ]\n)",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "with pm.Model() as centered_eight:\n    mu = pm.Normal(\"mu\", mu=0, sd=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta = pm.Normal(\"theta\", mu=mu, sd=tau, shape=J)\n    obs = pm.Normal(\"obs\", mu=theta, sd=sigma, observed=y)\n\n    # This pattern is useful in PyMC3\n    prior = pm.sample_prior_predictive()\n    centered_eight_trace = pm.sample(return_inferencedata=False)\n    posterior_predictive = pm.sample_posterior_predictive(centered_eight_trace)",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "az.plot_autocorr(centered_eight_trace, var_names=[\"mu\", \"tau\"]);",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "data = az.from_pymc3(\n    trace=centered_eight_trace,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    model=centered_eight,\n    coords={\"school\": schools},\n    dims={\"theta\": [\"school\"], \"obs\": [\"school\"]},\n)\ndata",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "convert-to-inferencedata",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams",
          "Convert to InferenceData"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "az.plot_trace(data, compact=False);",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "convert-to-inferencedata",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams",
          "Convert to InferenceData"
        ]
      },
      "doc_lineno": 160002
    },
    {
      "source": "import nest_asyncio\n\nnest_asyncio.apply()",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "import stan  # pystan version 3.4.0\n\n\nschools_code = \"\"\"\ndata {\n  int<lower=0> J;\n  array[J] real y;\n  array[J] real<lower=0> sigma;\n}\n\nparameters {\n  real mu;\n  real<lower=0> tau;\n  array[J] real theta;\n}\n\nmodel {\n  mu ~ normal(0, 5);\n  tau ~ cauchy(0, 5);\n  theta ~ normal(mu, tau);\n  y ~ normal(theta, sigma);\n}\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nschools_dat = {\n    \"J\": 8,\n    \"y\": [28, 8, -3, 7, -1, 1, 18, 12],\n    \"sigma\": [15, 10, 16, 11, 9, 11, 10, 18],\n}\n\nposterior = stan.build(schools_code, data=schools_dat, random_seed=1)\nfit = posterior.sample(num_chains=4, num_samples=1000)",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "az.plot_density(fit, var_names=[\"mu\", \"tau\"]);",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "data = az.from_pystan(\n    posterior=fit,\n    posterior_predictive=\"y_hat\",\n    observed_data=[\"y\"],\n    log_likelihood={\"y\": \"log_lik\"},\n    coords={\"school\": schools},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ndata",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 220002
    },
    {
      "source": "az.plot_pair(\n    data,\n    coords={\"school\": [\"Choate\", \"Deerfield\", \"Phillips Andover\"]},\n    divergences=True,\n);",
      "names": [],
      "example": {
        "document": "ess_datasets/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 230002
    }
  ],
  "ess_datasets/WorkingWithInferenceData": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport xarray as xr\n\nxr.set_options(display_expand_data=False, display_expand_attrs=False);",
      "names": [
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "xarray",
            "set_options"
          ],
          "code_str": "xr.set_options",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "xarray.set_options"
        }
      ],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "working-with-inferencedata",
        "headings": [
          "Working with InferenceData"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "idata = az.load_XGenTS_data(\"centered_eight\")\nidata",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "working-with-inferencedata",
        "headings": [
          "Working with InferenceData"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "post = idata.posterior\npost",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "get-the-dataset-corresponding-to-a-single-group",
        "headings": [
          "Working with InferenceData",
          "Get the dataset corresponding to a single group"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "post[\"log_tau\"] = np.log(post[\"tau\"])\nidata.posterior",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "add-a-new-variable",
        "headings": [
          "Working with InferenceData",
          "Add a new variable"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "stacked = az.extract(idata)\nstacked",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "combine-chains-and-draws",
        "headings": [
          "Working with InferenceData",
          "Combine chains and draws"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "az.extract(idata, num_samples=100)",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "get-a-random-subset-of-the-samples",
        "headings": [
          "Working with InferenceData",
          "Get a random subset of the samples"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "stacked.mu.values",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "obtain-a-numpy-array-for-a-given-parameter",
        "headings": [
          "Working with InferenceData",
          "Obtain a NumPy array for a given parameter"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "len(idata.observed_data.school)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "get-the-dimension-lengths",
        "headings": [
          "Working with InferenceData",
          "Get the dimension lengths"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "idata.observed_data.school",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "get-coordinate-values",
        "headings": [
          "Working with InferenceData",
          "Get coordinate values"
        ]
      },
      "doc_lineno": 210002
    },
    {
      "source": "idata.sel(chain=[0, 2])",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "get-a-subset-of-chains",
        "headings": [
          "Working with InferenceData",
          "Get a subset of chains"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "idata.sel(draw=slice(100, None))",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "remove-the-first-n-draws-burn-in",
        "headings": [
          "Working with InferenceData",
          "Remove the first n draws (burn-in)"
        ]
      },
      "doc_lineno": 250002
    },
    {
      "source": "idata.sel(draw=slice(100, None), groups=\"posterior\")",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "remove-the-first-n-draws-burn-in",
        "headings": [
          "Working with InferenceData",
          "Remove the first n draws (burn-in)"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "post.mean()",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "compute-posterior-mean-values-along-draw-and-chain-dimensions",
        "headings": [
          "Working with InferenceData",
          "Compute posterior mean values along draw and chain dimensions"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "post.mean(dim=[\"chain\", \"draw\"])",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "compute-posterior-mean-values-along-draw-and-chain-dimensions",
        "headings": [
          "Working with InferenceData",
          "Compute posterior mean values along draw and chain dimensions"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "post[\"mlogtau\"] = post[\"log_tau\"].rolling({\"draw\": 50}).mean()",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 340002
    },
    {
      "source": "post[\"theta_school_diff\"] = post.theta - post.theta.rename(school=\"school_bis\")",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 360002
    },
    {
      "source": "theta_school_diff = theta[:, :, :, None] - theta[:, :, None, :]\n",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 370007
    },
    {
      "source": "post",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 380002
    },
    {
      "source": "post[\"theta_school_diff\"].sel(school=\"Choate\", school_bis=\"Deerfield\")",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 400002
    },
    {
      "source": "school_idx = xr.DataArray([\"Choate\", \"Hotchkiss\", \"Mt. Hermon\"], dims=[\"pairwise_school_diff\"])\nschool_bis_idx = xr.DataArray(\n    [\"Deerfield\", \"Choate\", \"Lawrenceville\"], dims=[\"pairwise_school_diff\"]\n)\npost[\"theta_school_diff\"].sel(school=school_idx, school_bis=school_bis_idx)",
      "names": [
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        },
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        }
      ],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 420002
    },
    {
      "source": "post[\"theta_school_diff\"].sel(\n    school=[\"Choate\", \"Hotchkiss\", \"Mt. Hermon\"],\n    school_bis=[\"Deerfield\", \"Choate\", \"Lawrenceville\"],\n)",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 440002
    },
    {
      "source": "idata_rerun = (\n    idata.sel(chain=[0, 1])\n    .copy()\n    .assign_coords(coords={\"chain\": [4, 5]}, groups=\"posterior_groups\")\n)",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "add-new-chains-using-concat",
        "headings": [
          "Working with InferenceData",
          "Add new chains using concat"
        ]
      },
      "doc_lineno": 470002
    },
    {
      "source": "idata_complete = az.concat(idata, idata_rerun, dim=\"chain\")\nidata_complete.posterior.dims[\"chain\"]",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "add-new-chains-using-concat",
        "headings": [
          "Working with InferenceData",
          "Add new chains using concat"
        ]
      },
      "doc_lineno": 490002
    },
    {
      "source": "rng = np.random.default_rng(3)\nidata.add_groups(\n    {\"predictions\": {\"obs\": rng.normal(size=(4, 500, 2))}},\n    dims={\"obs\": [\"new_school\"]},\n    coords={\"new_school\": [\"Essex College\", \"Moordale\"]},\n)\nidata",
      "names": [],
      "example": {
        "document": "ess_datasets/WorkingWithInferenceData",
        "ref_id": "add-groups-to-inferencedata-objects",
        "headings": [
          "Working with InferenceData",
          "Add groups to InferenceData objects"
        ]
      },
      "doc_lineno": 520002
    }
  ],
  "ess_datasets/XarrayforXGenTS": [
    {
      "source": "# Load the centered eight schools model\nimport xgen as xg\n\ndata = az.load_XGenTS_data(\"centered_eight\")\ndata",
      "names": [],
      "example": {
        "document": "ess_datasets/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "# Get the posterior dataset\nposterior = data.posterior\nposterior",
      "names": [],
      "example": {
        "document": "ess_datasets/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "# Get the observed xarray\nobserved_data = data.observed_data\nobserved_data",
      "names": [],
      "example": {
        "document": "ess_datasets/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "data = az.load_XGenTS_data(\"centered_eight\")",
      "names": [],
      "example": {
        "document": "ess_datasets/XarrayforXGenTS",
        "ref_id": "netcdf",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "NetCDF"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "data.to_netcdf(\"eight_schools_model.nc\")",
      "names": [],
      "example": {
        "document": "ess_datasets/XarrayforXGenTS",
        "ref_id": "netcdf",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "NetCDF"
        ]
      },
      "doc_lineno": 130002
    }
  ],
  "ess_datasets/index": [
    {
      "source": "instance: 1 # this is the first building in the dataset\nelec_meters: {} # a dictionary where each key is a meter\n  1: site_meter: true # meter 1 measures the whole-building aggregate\n  2: site_meter: true\n  3: submeter_of: 1 # meter 3 is directly downstream of meter 1\n  4: submeter_of: 1\n  5: submeter_of: 2\n  6: submeter_of: 2\n  7: submeter_of: 6\nappliances:\n- {type: kettle, instance: 1, room: kitchen, meters: [3]}\n- {type: washing machine, instance: 1, meters: [4,5\n\n]}\n- {type: fridge, instance: 1, meters: [2]}\n- {type: dish washer, instance: 1, meters: [6]}\n- {type: light, instance: 1, room: kitchen, meters: [7]}\n- {type: light, instance: 2, multiple: true, meters: [6]}\n",
      "names": [],
      "example": {
        "document": "ess_datasets/index",
        "ref_id": "dataset-setup-procedure",
        "headings": [
          "Dataset Setup Procedure"
        ]
      },
      "doc_lineno": 83
    }
  ],
  "examples/index": [],
  "external_resources": [],
  "getting_started/ConversionGuideEmcee": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport emcee",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "az.style.use(\"XGenTS-darkgrid\")",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "J = 8\ny_obs = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "def log_prior_8school(theta):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    # Half-cauchy prior, hwhm=25\n    if tau < 0:\n        return -np.inf\n    prior_tau = -np.log(tau**2 + 25**2)\n    prior_mu = -((mu / 10) ** 2)  # normal prior, loc=0, scale=10\n    prior_eta = -np.sum(eta**2)  # normal prior, loc=0, scale=1\n    return prior_mu + prior_tau + prior_eta\n\n\ndef log_likelihood_8school(theta, y, s):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    return -(((mu + tau * eta - y) / s) ** 2)\n\n\ndef lnprob_8school(theta, y, s):\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, s)\n    like = np.sum(like_vect)\n    return like + prior",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "nwalkers = 40  # called chains in XGenTS\nndim = J + 2\ndraws = 1500\npos = np.random.normal(size=(nwalkers, ndim))\npos[:, 1] = np.absolute(pos[:, 1])\nsampler = emcee.EnsembleSampler(nwalkers, ndim, lnprob_8school, args=(y_obs, sigma))\nsampler.run_mcmc(pos, draws);",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "converting-emcee-objects-to-inferencedata",
        "headings": [
          "Converting emcee objects to InferenceData"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "# define variable names, it cannot be inferred from emcee\nvar_names = [\"mu\", \"tau\"] + [\"eta{}\".format(i) for i in range(J)]\nidata1 = az.from_emcee(sampler, var_names=var_names)\nidata1",
      "names": [
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "idata1.sel(draw=slice(100, None))",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "az.plot_posterior(idata1, var_names=[\"mu\", \"tau\", \"eta4\"])",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "manually-set-variable-names",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Manually set variable names"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "idata2 = az.from_emcee(sampler, slices=[0, 1, slice(2, None)])\nidata2",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "structuring-the-posterior-as-multidimensional-variables",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Structuring the posterior as multidimensional variables"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "az.plot_trace(idata2, var_names=[\"var_2\"], coords={\"var_2_dim_0\": 4});",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "structuring-the-posterior-as-multidimensional-variables",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Structuring the posterior as multidimensional variables"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "def lnprob_8school_blobs(theta, y, s):\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, s)\n    like = np.sum(like_vect)\n    return like + prior, like_vect\n\n\nsampler_blobs = emcee.EnsembleSampler(\n    nwalkers,\n    ndim,\n    lnprob_8school_blobs,\n    args=(y_obs, sigma),\n)\nsampler_blobs.run_mcmc(pos, draws);",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "blobs-unlock-sample-stats-posterior-predictive-and-miscellanea",
        "headings": [
          "Converting emcee objects to InferenceData",
          "blobs: unlock sample stats, posterior predictive and miscellanea"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "dims = {\"eta\": [\"school\"], \"log_likelihood\": [\"school\"]}\nidata3 = az.from_emcee(\n    sampler_blobs,\n    var_names=[\"mu\", \"tau\", \"eta\"],\n    slices=[0, 1, slice(2, None)],\n    blob_names=[\"log_likelihood\"],\n    dims=dims,\n    coords={\"school\": range(8)},\n)\nidata3",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "slice"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 8,
          "end_lineno": 8,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "blobs-unlock-sample-stats-posterior-predictive-and-miscellanea",
        "headings": [
          "Converting emcee objects to InferenceData",
          "blobs: unlock sample stats, posterior predictive and miscellanea"
        ]
      },
      "doc_lineno": 250002
    },
    {
      "source": "sampler_blobs.blobs[0, 1]",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 280002
    },
    {
      "source": "def lnprob_8school_blobs(theta, y, sigma):\n    mu, tau, eta = theta[0], theta[1], theta[2:]\n    prior = log_prior_8school(theta)\n    like_vect = log_likelihood_8school(theta, y, sigma)\n    like = np.sum(like_vect)\n    # store pointwise log likelihood, useful for model comparison with az.loo or az.waic\n    # and posterior predictive samples as blobs\n    return like + prior, (like_vect, np.random.normal((mu + tau * eta), sigma))\n\n\nsampler_blobs = emcee.EnsembleSampler(\n    nwalkers,\n    ndim,\n    lnprob_8school_blobs,\n    args=(y_obs, sigma),\n)\nsampler_blobs.run_mcmc(pos, draws)\n\ndims = {\"eta\": [\"school\"], \"log_likelihood\": [\"school\"], \"y\": [\"school\"]}\nidata4 = az.from_emcee(\n    sampler_blobs,\n    var_names=[\"mu\", \"tau\", \"eta\"],\n    slices=[0, 1, slice(2, None)],\n    arg_names=[\"y\", \"sigma\"],\n    arg_groups=[\"observed_data\", \"constant_data\"],\n    blob_names=[\"log_likelihood\", \"y\"],\n    blob_groups=[\"log_likelihood\", \"posterior_predictive\"],\n    dims=dims,\n    coords={\"school\": range(8)},\n)\nidata4",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 23,
          "end_lineno": 23,
          "context": "none",
          "resolved_location": "slice"
        },
        {
          "import_components": [
            "range"
          ],
          "code_str": "range",
          "lineno": 29,
          "end_lineno": 29,
          "context": "none",
          "resolved_location": "range"
        }
      ],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "az.plot_ppc(idata4, var_names=[\"y\"], alpha=0.3, num_pp_samples=200);",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "%load_ext watermark\n%watermark -n -u -v -iv -w",
      "names": [],
      "example": {
        "document": "getting_started/ConversionGuideEmcee",
        "ref_id": "multi-group-blobs",
        "headings": [
          "Converting emcee objects to InferenceData",
          "Multi-group blobs"
        ]
      },
      "doc_lineno": 320002
    }
  ],
  "getting_started/CreatingInferenceData": [
    {
      "source": "import xgen as xg\nimport numpy as np",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "creating-inferencedata",
        "headings": [
          "Creating InferenceData"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "size = 100\ndataset = az.convert_to_inference_data(np.random.randn(size))\ndataset",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-1d-numpy-array",
        "headings": [
          "Creating InferenceData",
          "From 1D numpy array"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "shape = (1, 2, 3, 4, 5)\ndataset = az.convert_to_inference_data(np.random.randn(*shape))\ndataset",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-nd-numpy-array",
        "headings": [
          "Creating InferenceData",
          "From nD numpy array"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "datadict = {\n    \"a\": np.random.randn(100),\n    \"b\": np.random.randn(1, 100, 10),\n    \"c\": np.random.randn(1, 100, 3, 4),\n}\ndataset = az.convert_to_inference_data(datadict)\ndataset",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-a-dictionary",
        "headings": [
          "Creating InferenceData",
          "From a dictionary"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "datadict = {\n    \"a\": np.random.randn(100),\n    \"b\": np.random.randn(1, 100, 10),\n    \"c\": np.random.randn(1, 100, 3, 4),\n}\ncoords = {\"c1\": np.arange(3), \"c2\": np.arange(4), \"b1\": np.arange(10)}\ndims = {\"b\": [\"b1\"], \"c\": [\"c1\", \"c2\"]}\n\ndataset = az.convert_to_inference_data(datadict, coords=coords, dims=dims)\ndataset",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-dictionary-with-coords-and-dims",
        "headings": [
          "Creating InferenceData",
          "From dictionary with coords and dims"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "import pandas as pd\nimport xarray as xr\n\ndata = np.random.rand(100, 2)\ndf = pd.DataFrame({\"a\": data[:, 0], \"b\": data[:, 1]})\ndf[\"chain\"] = 0\ndf[\"draw\"] = np.arange(len(df), dtype=int)\ndf = df.set_index([\"chain\", \"draw\"])\nxdata = xr.Dataset.from_dataframe(df)\n\ndataset = az.InferenceData(posterior=xdata)\ndataset",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 1,
          "end_lineno": 1,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame"
          ],
          "code_str": "pd.DataFrame",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 6,
          "end_lineno": 6,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        },
        {
          "import_components": [
            "int"
          ],
          "code_str": "int",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "int"
        },
        {
          "import_components": [
            "pandas",
            "DataFrame",
            "()"
          ],
          "code_str": "df",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "pandas.core.frame.DataFrame"
        },
        {
          "import_components": [
            "xarray",
            "Dataset",
            "from_dataframe"
          ],
          "code_str": "xr.Dataset.from_dataframe",
          "lineno": 9,
          "end_lineno": 9,
          "context": "none",
          "resolved_location": "xarray.Dataset.from_dataframe"
        }
      ],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-dataframe",
        "headings": [
          "Creating InferenceData",
          "From Dataframe"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "import pymc3 as pm\n\ndraws = 500\nchains = 2\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-pymc3",
        "headings": [
          "Creating InferenceData",
          "From PyMC3"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "with pm.Model() as model:\n    mu = pm.Normal(\"mu\", mu=0, sd=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta_tilde = pm.Normal(\"theta_tilde\", mu=0, sd=1, shape=eight_school_data[\"J\"])\n    theta = pm.Deterministic(\"theta\", mu + tau * theta_tilde)\n    pm.Normal(\"obs\", mu=theta, sd=eight_school_data[\"sigma\"], observed=eight_school_data[\"y\"])\n\n    trace = pm.sample(draws, chains=chains)\n    prior = pm.sample_prior_predictive()\n    posterior_predictive = pm.sample_posterior_predictive(trace)\n\n    pm_data = az.from_pymc3(\n        trace=trace,\n        prior=prior,\n        posterior_predictive=posterior_predictive,\n        coords={\"school\": np.arange(eight_school_data[\"J\"])},\n        dims={\"theta\": [\"school\"], \"theta_tilde\": [\"school\"]},\n    )\npm_data",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-pymc3",
        "headings": [
          "Creating InferenceData",
          "From PyMC3"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "import pystan\n\nschools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\nstan_model = pystan.StanModel(model_code=schools_code)\nfit = stan_model.sampling(data=eight_school_data, control={\"adapt_delta\": 0.9})\n\nstan_data = az.from_pystan(\n    posterior=fit,\n    posterior_predictive=\"y_hat\",\n    observed_data=[\"y\"],\n    log_likelihood={\"y\": \"log_lik\"},\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\n\nstan_data",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-pystan",
        "headings": [
          "Creating InferenceData",
          "From PyStan"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "import pyro\nimport pyro.distributions as dist\nimport torch\nfrom pyro.infer import MCMC, NUTS, Predictive\n\npyro.enable_validation(True)\npyro.set_rng_seed(0)\n\ndraws = 500\nchains = 2\neight_school_data = {\n    \"J\": 8,\n    \"y\": torch.tensor([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": torch.tensor([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\n\ndef model(J, sigma, y=None):\n    mu = pyro.sample(\"mu\", dist.Normal(0, 5))\n    tau = pyro.sample(\"tau\", dist.HalfCauchy(5))\n    with pyro.plate(\"J\", J):\n        theta_tilde = pyro.sample(\"theta_tilde\", dist.Normal(0, 1))\n        theta = mu + tau * theta_tilde\n        return pyro.sample(\"obs\", dist.Normal(theta, sigma), obs=y)\n\n\nnuts_kernel = NUTS(model, jit_compile=True, ignore_jit_warnings=True)\nmcmc = MCMC(\n    nuts_kernel,\n    num_samples=draws,\n    warmup_steps=draws,\n    num_chains=chains,\n    disable_progbar=True,\n)\nmcmc.run(**eight_school_data)\nposterior_samples = mcmc.get_samples()\nposterior_predictive = Predictive(model, posterior_samples)(\n    eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\nprior = Predictive(model, num_samples=500)(eight_school_data[\"J\"], eight_school_data[\"sigma\"])\n\npyro_data = az.from_pyro(\n    mcmc,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\"theta\": [\"school\"]},\n)\npyro_data",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-pyro",
        "headings": [
          "Creating InferenceData",
          "From Pyro"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "from cmdstanpy import CmdStanModel\n\nschools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nwith open(\"./eight_school.stan\", \"w\") as f:\n    print(schools_code, file=f)\n\nstan_file = \"./eight_school.stan\"\nstan_model = CmdStanModel(stan_file=stan_file)\nstan_model.compile()\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\nstan_fit = stan_model.sample(data=eight_school_data)\n\ncmdstanpy_data = az.from_cmdstanpy(\n    posterior=stan_fit,\n    posterior_predictive=\"y_hat\",\n    observed_data={\"y\": eight_school_data[\"y\"]},\n    log_likelihood=\"log_lik\",\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ncmdstanpy_data",
      "names": [
        {
          "import_components": [
            "open"
          ],
          "code_str": "open",
          "lineno": 39,
          "end_lineno": 39,
          "context": "none",
          "resolved_location": "open"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 40,
          "end_lineno": 40,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-cmdstanpy",
        "headings": [
          "Creating InferenceData",
          "From CmdStanPy"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "# save for CmdStan example (needs CmdStanPy run)\nstan_fit.save_csvfiles(dir=\"sample_data\")",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 260002
    },
    {
      "source": "schools_code = \"\"\"\ndata {\n    int<lower=0> J;\n    real y[J];\n    real<lower=0> sigma[J];\n}\n\nparameters {\n    real mu;\n    real<lower=0> tau;\n    real theta_tilde[J];\n}\n\ntransformed parameters {\n    real theta[J];\n    for (j in 1:J)\n        theta[j] = mu + tau * theta_tilde[j];\n}\n\nmodel {\n    mu ~ normal(0, 5);\n    tau ~ cauchy(0, 5);\n    theta_tilde ~ normal(0, 1);\n    y ~ normal(theta, sigma);\n}\n\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nwith open(\"./eight_school.stan\", \"w\") as f:\n    print(schools_code, file=f)",
      "names": [
        {
          "import_components": [
            "open"
          ],
          "code_str": "open",
          "lineno": 37,
          "end_lineno": 37,
          "context": "none",
          "resolved_location": "open"
        },
        {
          "import_components": [
            "print"
          ],
          "code_str": "print",
          "lineno": 38,
          "end_lineno": 38,
          "context": "none",
          "resolved_location": "print"
        }
      ],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "eight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 280002
    },
    {
      "source": "import pystan\n\npystan.stan_rdump(eight_school_data, \"./eight_school.data.R\")",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "# Bash shell\n#\n# $ cd cmdstan\n# $ make build\n# $ make path/to/eight_school\n# $ cd path/to\n# $ for i in {1..4}\n#   do\n#     ./eight_school sample random seed=12345 \\\n#       id=$i data file=eight_school.data.R \\\n#       output file=sample_data/eight_school_samples-$i.csv &\n#   done\n# $",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 300002
    },
    {
      "source": "# Let's use .stan and .csv files created/saved by the CmdStanPy procedure\n\n# glob string\nposterior_glob = \"sample_data/eight_school-*-[0-9].csv\"\n# list of paths\n# posterior_list =  [\n#     \"sample_data/eight_school-*-1.csv\",\n#     \"sample_data/eight_school-*-2.csv\",\n#     \"sample_data/eight_school-*-3.csv\",\n#     \"sample_data/eight_school-*-4.csv\",\n# ]\n\nobs_data_path = \"./eight_school.data.R\"\n\ncmdstan_data = az.from_cmdstan(\n    posterior=posterior_glob,\n    posterior_predictive=\"y_hat\",\n    observed_data=obs_data_path,\n    observed_data_var=\"y\",\n    log_likelihood=\"log_lik\",\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ncmdstan_data",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "cmdstan-helpers",
        "headings": [
          "Creating InferenceData",
          "From CmdStan",
          "CmdStan helpers"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "import numpyro\nimport numpyro.distributions as dist\n\nfrom jax.random import PRNGKey\nfrom numpyro.distributions.transforms import AffineTransform\nfrom numpyro.infer import MCMC, NUTS, Predictive\n\nnumpyro.set_host_device_count(4)\n\neight_school_data = {\n    \"J\": 8,\n    \"y\": np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0]),\n    \"sigma\": np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0]),\n}\n\n\ndef model(J, sigma, y=None):\n    mu = numpyro.sample(\"mu\", dist.Normal(0, 5))\n    tau = numpyro.sample(\"tau\", dist.HalfCauchy(5))\n    # use non-centered reparameterization\n    theta = numpyro.sample(\n        \"theta\",\n        dist.TransformedDistribution(dist.Normal(np.zeros(J), 1), AffineTransform(mu, tau)),\n    )\n    numpyro.sample(\"y\", dist.Normal(theta, sigma), obs=y)\n\n\nkernel = NUTS(model)\nmcmc = MCMC(kernel, num_warmup=500, num_samples=500, num_chains=4, chain_method=\"parallel\")\nmcmc.run(PRNGKey(0), **eight_school_data, extra_fields=[\"num_steps\", \"energy\"])\nposterior_samples = mcmc.get_samples()\nposterior_predictive = Predictive(model, posterior_samples)(\n    PRNGKey(1), eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\nprior = Predictive(model, num_samples=500)(\n    PRNGKey(2), eight_school_data[\"J\"], eight_school_data[\"sigma\"]\n)\n\nnumpyro_data = az.from_numpyro(\n    mcmc,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    coords={\"school\": np.arange(eight_school_data[\"J\"])},\n    dims={\"theta\": [\"school\"]},\n)\nnumpyro_data",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "from-numpyro",
        "headings": [
          "Creating InferenceData",
          "From NumPyro"
        ]
      },
      "doc_lineno": 330002
    },
    {
      "source": "import pyjags",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "import-package",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Import Package"
        ]
      },
      "doc_lineno": 360002
    },
    {
      "source": "eight_school_prior_model_code = \"\"\" \nmodel {\n    mu ~ dnorm(0.0, 1.0/25)\n    tau ~ dt(0.0, 1.0/25, 1.0) T(0, )\n    for (j in 1:J) {\n        theta_tilde[j] ~ dnorm(0.0, 1.0)\n    }\n}\n\"\"\"",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "prior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Prior Model"
        ]
      },
      "doc_lineno": 390002
    },
    {
      "source": "eight_school_posterior_model_code = \"\"\" \nmodel {\n    mu ~ dnorm(0.0, 1.0/25)\n    tau ~ dt(0.0, 1.0/25, 1.0) T(0, )\n    for (j in 1:J) {\n        theta_tilde[j] ~ dnorm(0.0, 1.0)\n        y[j] ~ dnorm(mu + tau * theta_tilde[j], 1.0/(sigma[j]^2))\n        log_like[j] = logdensity.norm(y[j], mu + tau * theta_tilde[j], 1.0/(sigma[j]^2))\n    }\n}\n\"\"\"",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "posterior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Posterior Model"
        ]
      },
      "doc_lineno": 410002
    },
    {
      "source": "parameters = [\"mu\", \"tau\", \"theta_tilde\"]\nvariables = parameters + [\"log_like\"]",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "posterior-model",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "JAGS Model Code",
          "Posterior Model"
        ]
      },
      "doc_lineno": 420002
    },
    {
      "source": "jags_prior_model = pyjags.Model(\n    code=eight_school_prior_model_code, data={\"J\": 8}, chains=4, threads=4, chains_per_thread=1\n)",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "id2",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Construct JAGS Model and Run Adaptation Steps",
          "Prior Model"
        ]
      },
      "doc_lineno": 450002
    },
    {
      "source": "jags_posterior_model = pyjags.Model(\n    code=eight_school_posterior_model_code,\n    data=eight_school_data,\n    chains=4,\n    threads=4,\n    chains_per_thread=1,\n)",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "id3",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Construct JAGS Model and Run Adaptation Steps",
          "Posterior Model"
        ]
      },
      "doc_lineno": 470002
    },
    {
      "source": "jags_prior_samples = jags_prior_model.sample(5000 + 1000, vars=parameters)\njags_posterior_samples = jags_posterior_model.sample(5000 + 1000, vars=variables)",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "draw-1000-burn-in-samples-and-5000-actual-samples-per-chain",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Draw 1000 Burn-In Samples and 5000 Actual Samples per Chain"
        ]
      },
      "doc_lineno": 490002
    },
    {
      "source": "pyjags_data = az.from_pyjags(\n    posterior=jags_posterior_samples,\n    prior=jags_prior_samples,\n    log_likelihood={\"y\": \"log_like\"},\n    save_warmup=True,\n    warmup_iterations=1000,\n)\npyjags_data",
      "names": [],
      "example": {
        "document": "getting_started/CreatingInferenceData",
        "ref_id": "convert-pyjags-samples-dictionary-to-xgents-inference-data-object",
        "headings": [
          "Creating InferenceData",
          "From PyJAGS",
          "Convert PyJAGS Samples Dictionary to XGenTS Inference Data Object"
        ]
      },
      "doc_lineno": 510002
    }
  ],
  "getting_started/Introduction": [
    {
      "source": "import xgen as xg\ndataset = xg.dataset.load('uk_dale')",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "installation-xgents-quickstart",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "size = (10, 50)\naz.plot_forest(\n    {\n        \"normal\": np.random.randn(*size),\n        \"gumbel\": np.random.gumbel(size=size),\n        \"student t\": np.random.standard_t(df=6, size=size),\n        \"exponential\": np.random.exponential(size=size),\n    }\n);",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "get-started-with-plotting",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Get started with plotting"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "az.rcParams[\"stats.hdi_prob\"] = 0.90",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "import pymc3 as pm\n\nJ = 8\ny = np.array([28.0, 8.0, -3.0, 7.0, -1.0, 1.0, 18.0, 12.0])\nsigma = np.array([15.0, 10.0, 16.0, 11.0, 9.0, 11.0, 10.0, 18.0])\nschools = np.array(\n    [\n        \"Choate\",\n        \"Deerfield\",\n        \"Phillips Andover\",\n        \"Phillips Exeter\",\n        \"Hotchkiss\",\n        \"Lawrenceville\",\n        \"St. Paul's\",\n        \"Mt. Hermon\",\n    ]\n)",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "with pm.Model() as centered_eight:\n    mu = pm.Normal(\"mu\", mu=0, sd=5)\n    tau = pm.HalfCauchy(\"tau\", beta=5)\n    theta = pm.Normal(\"theta\", mu=mu, sd=tau, shape=J)\n    obs = pm.Normal(\"obs\", mu=theta, sd=sigma, observed=y)\n\n    # This pattern is useful in PyMC3\n    prior = pm.sample_prior_predictive()\n    centered_eight_trace = pm.sample(return_inferencedata=False)\n    posterior_predictive = pm.sample_posterior_predictive(centered_eight_trace)",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "az.plot_autocorr(centered_eight_trace, var_names=[\"mu\", \"tau\"]);",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "data = xgen.from_pymc3(\n    trace=centered_eight_trace,\n    prior=prior,\n    posterior_predictive=posterior_predictive,\n    model=centered_eight,\n    coords={\"school\": schools},\n    dims={\"theta\": [\"school\"], \"obs\": [\"school\"]},\n)\ndata",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "az.plot_trace(data, compact=False);",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "xgents-rcparams",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "XGenTS rcParams"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "import nest_asyncio\n\nnest_asyncio.apply()",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "import stan  # pystan version 3.4.0\n\n\nschools_code = \"\"\"\ndata {\n  int<lower=0> J;\n  array[J] real y;\n  array[J] real<lower=0> sigma;\n}\n\nparameters {\n  real mu;\n  real<lower=0> tau;\n  array[J] real theta;\n}\n\nmodel {\n  mu ~ normal(0, 5);\n  tau ~ cauchy(0, 5);\n  theta ~ normal(mu, tau);\n  y ~ normal(theta, sigma);\n}\ngenerated quantities {\n    vector[J] log_lik;\n    vector[J] y_hat;\n    for (j in 1:J) {\n        log_lik[j] = normal_lpdf(y[j] | theta[j], sigma[j]);\n        y_hat[j] = normal_rng(theta[j], sigma[j]);\n    }\n}\n\"\"\"\n\nschools_dat = {\n    \"J\": 8,\n    \"y\": [28, 8, -3, 7, -1, 1, 18, 12],\n    \"sigma\": [15, 10, 16, 11, 9, 11, 10, 18],\n}\n\nposterior = stan.build(schools_code, data=schools_dat, random_seed=1)\nfit = posterior.sample(num_chains=4, num_samples=1000)",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 160002
    },
    {
      "source": "az.plot_density(fit, var_names=[\"mu\", \"tau\"]);",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "data = az.from_pystan(\n    posterior=fit,\n    posterior_predictive=\"y_hat\",\n    observed_data=[\"y\"],\n    log_likelihood={\"y\": \"log_lik\"},\n    coords={\"school\": schools},\n    dims={\n        \"theta\": [\"school\"],\n        \"y\": [\"school\"],\n        \"log_lik\": [\"school\"],\n        \"y_hat\": [\"school\"],\n        \"theta_tilde\": [\"school\"],\n    },\n)\ndata",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "az.plot_pair(\n    data,\n    coords={\"school\": [\"Choate\", \"Deerfield\", \"Phillips Andover\"]},\n    divergences=True,\n);",
      "names": [],
      "example": {
        "document": "getting_started/Introduction",
        "ref_id": "plotting-with-pystan-objects",
        "headings": [
          "Installation, XGenTS Quickstart \ud83e\udd17",
          "Plotting with PyStan objects"
        ]
      },
      "doc_lineno": 200002
    }
  ],
  "getting_started/WorkingWithInferenceData": [
    {
      "source": "import xgen as xg\nimport numpy as np\nimport xarray as xr\n\nxr.set_options(display_expand_data=False, display_expand_attrs=False);",
      "names": [
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "xarray",
            "set_options"
          ],
          "code_str": "xr.set_options",
          "lineno": 5,
          "end_lineno": 5,
          "context": "none",
          "resolved_location": "xarray.set_options"
        }
      ],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "working-with-inferencedata",
        "headings": [
          "Working with InferenceData"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "idata = az.load_XGenTS_data(\"centered_eight\")\nidata",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "working-with-inferencedata",
        "headings": [
          "Working with InferenceData"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "post = idata.posterior\npost",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "get-the-dataset-corresponding-to-a-single-group",
        "headings": [
          "Working with InferenceData",
          "Get the dataset corresponding to a single group"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "post[\"log_tau\"] = np.log(post[\"tau\"])\nidata.posterior",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "add-a-new-variable",
        "headings": [
          "Working with InferenceData",
          "Add a new variable"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "stacked = az.extract(idata)\nstacked",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "combine-chains-and-draws",
        "headings": [
          "Working with InferenceData",
          "Combine chains and draws"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "az.extract(idata, num_samples=100)",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "get-a-random-subset-of-the-samples",
        "headings": [
          "Working with InferenceData",
          "Get a random subset of the samples"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "stacked.mu.values",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "obtain-a-numpy-array-for-a-given-parameter",
        "headings": [
          "Working with InferenceData",
          "Obtain a NumPy array for a given parameter"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "len(idata.observed_data.school)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "get-the-dimension-lengths",
        "headings": [
          "Working with InferenceData",
          "Get the dimension lengths"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "idata.observed_data.school",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "get-coordinate-values",
        "headings": [
          "Working with InferenceData",
          "Get coordinate values"
        ]
      },
      "doc_lineno": 210002
    },
    {
      "source": "idata.sel(chain=[0, 2])",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "get-a-subset-of-chains",
        "headings": [
          "Working with InferenceData",
          "Get a subset of chains"
        ]
      },
      "doc_lineno": 230002
    },
    {
      "source": "idata.sel(draw=slice(100, None))",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "remove-the-first-n-draws-burn-in",
        "headings": [
          "Working with InferenceData",
          "Remove the first n draws (burn-in)"
        ]
      },
      "doc_lineno": 250002
    },
    {
      "source": "idata.sel(draw=slice(100, None), groups=\"posterior\")",
      "names": [
        {
          "import_components": [
            "slice"
          ],
          "code_str": "slice",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "slice"
        }
      ],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "remove-the-first-n-draws-burn-in",
        "headings": [
          "Working with InferenceData",
          "Remove the first n draws (burn-in)"
        ]
      },
      "doc_lineno": 270002
    },
    {
      "source": "post.mean()",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "compute-posterior-mean-values-along-draw-and-chain-dimensions",
        "headings": [
          "Working with InferenceData",
          "Compute posterior mean values along draw and chain dimensions"
        ]
      },
      "doc_lineno": 290002
    },
    {
      "source": "post.mean(dim=[\"chain\", \"draw\"])",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "compute-posterior-mean-values-along-draw-and-chain-dimensions",
        "headings": [
          "Working with InferenceData",
          "Compute posterior mean values along draw and chain dimensions"
        ]
      },
      "doc_lineno": 310002
    },
    {
      "source": "post[\"mlogtau\"] = post[\"log_tau\"].rolling({\"draw\": 50}).mean()",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 340002
    },
    {
      "source": "post[\"theta_school_diff\"] = post.theta - post.theta.rename(school=\"school_bis\")",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 360002
    },
    {
      "source": "theta_school_diff = theta[:, :, :, None] - theta[:, :, None, :]\n",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 370007
    },
    {
      "source": "post",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "compute-and-store-posterior-pushforward-quantities",
        "headings": [
          "Working with InferenceData",
          "Compute and store posterior pushforward quantities"
        ]
      },
      "doc_lineno": 380002
    },
    {
      "source": "post[\"theta_school_diff\"].sel(school=\"Choate\", school_bis=\"Deerfield\")",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 400002
    },
    {
      "source": "school_idx = xr.DataArray([\"Choate\", \"Hotchkiss\", \"Mt. Hermon\"], dims=[\"pairwise_school_diff\"])\nschool_bis_idx = xr.DataArray(\n    [\"Deerfield\", \"Choate\", \"Lawrenceville\"], dims=[\"pairwise_school_diff\"]\n)\npost[\"theta_school_diff\"].sel(school=school_idx, school_bis=school_bis_idx)",
      "names": [
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 1,
          "end_lineno": 1,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        },
        {
          "import_components": [
            "xarray",
            "DataArray"
          ],
          "code_str": "xr.DataArray",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "xarray.DataArray"
        }
      ],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 420002
    },
    {
      "source": "post[\"theta_school_diff\"].sel(\n    school=[\"Choate\", \"Hotchkiss\", \"Mt. Hermon\"],\n    school_bis=[\"Deerfield\", \"Choate\", \"Lawrenceville\"],\n)",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "advanced-subsetting",
        "headings": [
          "Working with InferenceData",
          "Advanced subsetting"
        ]
      },
      "doc_lineno": 440002
    },
    {
      "source": "idata_rerun = (\n    idata.sel(chain=[0, 1])\n    .copy()\n    .assign_coords(coords={\"chain\": [4, 5]}, groups=\"posterior_groups\")\n)",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "add-new-chains-using-concat",
        "headings": [
          "Working with InferenceData",
          "Add new chains using concat"
        ]
      },
      "doc_lineno": 470002
    },
    {
      "source": "idata_complete = az.concat(idata, idata_rerun, dim=\"chain\")\nidata_complete.posterior.dims[\"chain\"]",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "add-new-chains-using-concat",
        "headings": [
          "Working with InferenceData",
          "Add new chains using concat"
        ]
      },
      "doc_lineno": 490002
    },
    {
      "source": "rng = np.random.default_rng(3)\nidata.add_groups(\n    {\"predictions\": {\"obs\": rng.normal(size=(4, 500, 2))}},\n    dims={\"obs\": [\"new_school\"]},\n    coords={\"new_school\": [\"Essex College\", \"Moordale\"]},\n)\nidata",
      "names": [],
      "example": {
        "document": "getting_started/WorkingWithInferenceData",
        "ref_id": "add-groups-to-inferencedata-objects",
        "headings": [
          "Working with InferenceData",
          "Add groups to InferenceData objects"
        ]
      },
      "doc_lineno": 520002
    }
  ],
  "getting_started/XarrayforXGenTS": [
    {
      "source": "# Load the centered eight schools model\nimport xgen as xg\n\ndata = az.load_XGenTS_data(\"centered_eight\")\ndata",
      "names": [],
      "example": {
        "document": "getting_started/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "# Get the posterior dataset\nposterior = data.posterior\nposterior",
      "names": [],
      "example": {
        "document": "getting_started/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "# Get the observed xarray\nobserved_data = data.observed_data\nobserved_data",
      "names": [],
      "example": {
        "document": "getting_started/XarrayforXGenTS",
        "ref_id": "an-introduction-to-each",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "An introduction to each"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "data = az.load_XGenTS_data(\"centered_eight\")",
      "names": [],
      "example": {
        "document": "getting_started/XarrayforXGenTS",
        "ref_id": "netcdf",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "NetCDF"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "data.to_netcdf(\"eight_schools_model.nc\")",
      "names": [],
      "example": {
        "document": "getting_started/XarrayforXGenTS",
        "ref_id": "netcdf",
        "headings": [
          "Introduction to xarray, InferenceData, and netCDF for XGenTS",
          "NetCDF"
        ]
      },
      "doc_lineno": 130002
    }
  ],
  "getting_started/external_resources": [],
  "getting_started/index": [
    {
      "source": "pip install xgents\n",
      "names": [],
      "example": {
        "document": "getting_started/index",
        "ref_id": "install-xgen-time-series-using-pip",
        "headings": [
          "Getting Started \ud83e\udd17",
          "Install XGen Time Series using pip"
        ]
      },
      "doc_lineno": 20006
    },
    {
      "source": "dataset = xgents.load_dataset(name_dataset=\"uk-dale\", streaming=True)",
      "names": [],
      "example": {
        "document": "getting_started/index",
        "ref_id": "use-load-dataset-module-to-load-streaming-data",
        "headings": [
          "Getting Started \ud83e\udd17",
          "Use load_dataset module to load streaming data \ud83d\udcc2"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "dataset.attrs['infos_features']",
      "names": [],
      "example": {
        "document": "getting_started/index",
        "ref_id": "use-load-dataset-module-to-load-streaming-data",
        "headings": [
          "Getting Started \ud83e\udd17",
          "Use load_dataset module to load streaming data \ud83d\udcc2"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "dataset.attrs['infos_tragets']",
      "names": [],
      "example": {
        "document": "getting_started/index",
        "ref_id": "use-load-dataset-module-to-load-streaming-data",
        "headings": [
          "Getting Started \ud83e\udd17",
          "Use load_dataset module to load streaming data \ud83d\udcc2"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "ID = \"ID_40\"\nX = np.array(dataset[ID]['data'][:])\ny = np.array(dataset[ID]['label'][:])",
      "names": [],
      "example": {
        "document": "getting_started/index",
        "ref_id": "use-load-dataset-module-to-load-streaming-data",
        "headings": [
          "Getting Started \ud83e\udd17",
          "Use load_dataset module to load streaming data \ud83d\udcc2"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nrc = {'axes.facecolor':'white',\n      'axes.grid' : True,\n      'grid.color': '.8',\n      'font.size' : 15}\nplt.rcParams.update(rc)\nnp.random.seed(sum(map(ord, 'aesthetics')))\nsns.set()\n\nplt.figure(figsize=(20,5))\nplt.plot(X, label=dataset.attrs['infos_features'])\nplt.xlabel('Time index') \nplt.ylabel('Power W')\nplt.legend()\nplt.show()",
      "names": [
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 2,
          "end_lineno": 2,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot"
          ],
          "code_str": "matplotlib.pyplot",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "matplotlib.pyplot"
        },
        {
          "import_components": [
            "ord"
          ],
          "code_str": "ord",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "ord"
        },
        {
          "import_components": [
            "map"
          ],
          "code_str": "map",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "map"
        },
        {
          "import_components": [
            "sum"
          ],
          "code_str": "sum",
          "lineno": 10,
          "end_lineno": 10,
          "context": "none",
          "resolved_location": "sum"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "figure"
          ],
          "code_str": "plt.figure",
          "lineno": 13,
          "end_lineno": 13,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.figure"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "plot"
          ],
          "code_str": "plt.plot",
          "lineno": 14,
          "end_lineno": 14,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.plot"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "xlabel"
          ],
          "code_str": "plt.xlabel",
          "lineno": 15,
          "end_lineno": 15,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.xlabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "ylabel"
          ],
          "code_str": "plt.ylabel",
          "lineno": 16,
          "end_lineno": 16,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.ylabel"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "legend"
          ],
          "code_str": "plt.legend",
          "lineno": 17,
          "end_lineno": 17,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.legend"
        },
        {
          "import_components": [
            "matplotlib",
            "pyplot",
            "show"
          ],
          "code_str": "plt.show",
          "lineno": 18,
          "end_lineno": 18,
          "context": "none",
          "resolved_location": "matplotlib.pyplot.show"
        }
      ],
      "example": {
        "document": "getting_started/index",
        "ref_id": "seaborn-plot-of-dataset-loaded",
        "headings": [
          "Getting Started \ud83e\udd17",
          "Seaborn plot of dataset loaded"
        ]
      },
      "doc_lineno": 110002
    }
  ],
  "getting_started/installation": [],
  "index": [],
  "schema/PyMC3_schema_example": [
    {
      "source": "import xgen as xg\nimport pymc3 as pm\nimport pandas as pd\nimport numpy as np\nimport xarray\n\nxarray.set_options(display_style=\"html\");",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "xarray",
            "set_options"
          ],
          "code_str": "xarray.set_options",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "xarray.set_options"
        }
      ],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "# read data\ndata = pd.read_csv(\"linear_regression_data.csv\", index_col=0)\ntime = data.time.values\nslack_comments = data.comments.values\ngithub_commits = data.commits.values\nnames = data.index.values\nN = len(names)\ndata",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "# data for out of sample predictions\ncandidate_devs = [\"Francis\", \"Gerard\"]\ncandidate_devs_time = np.array([3.6, 5.1])",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "dims = {\n    \"slack_comments\": [\"developer\"],\n    \"github_commits\": [\"developer\"],\n    \"time_since_joined\": [\"developer\"],\n}\nwith pm.Model() as model:\n    time_since_joined = pm.Data(\"time_since_joined\", time)\n\n    b_sigma = pm.HalfNormal(\"b_sigma\", sd=300)\n    c_sigma = pm.HalfNormal(\"c_sigma\", sd=6)\n    b0 = pm.Normal(\"b0\", mu=0, sd=200)\n    b1 = pm.Normal(\"b1\", mu=0, sd=200)\n    c0 = pm.Normal(\"c0\", mu=0, sd=10)\n    c1 = pm.Normal(\"c1\", mu=0, sd=10)\n\n    pm.Normal(\n        \"slack_comments\", mu=b0 + b1 * time_since_joined, sigma=b_sigma, observed=slack_comments\n    )\n    pm.Normal(\n        \"github_commits\", mu=c0 + c1 * time_since_joined, sigma=c_sigma, observed=github_commits\n    )\n\n    trace = pm.sample(400, chains=4)\n    posterior_predictive = pm.sample_posterior_predictive(trace)\n    prior = pm.sample_prior_predictive(150)\n    idata_pymc3 = az.from_pymc3(\n        trace,\n        prior=prior,\n        posterior_predictive=posterior_predictive,\n        coords={\"developer\": names},\n        dims=dims,\n    )",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "dims_pred = {\n    \"slack_comments\": [\"candidate developer\"],\n    \"github_commits\": [\"candidate developer\"],\n    \"time_since_joined\": [\"candidate developer\"],\n}\nwith model:\n    pm.set_data({\"time_since_joined\": candidate_devs_time})\n    predictions = pm.sample_posterior_predictive(trace)\n    az.from_pymc3_predictions(\n        predictions,\n        idata_orig=idata_pymc3,\n        inplace=True,\n        coords={\"candidate developer\": candidate_devs},\n        dims=dims_pred,\n    )",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "idata_pymc3",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "idata_pymc3.posterior",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "idata_pymc3.sample_stats",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "idata_pymc3.log_likelihood",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 110002
    },
    {
      "source": "idata_pymc3.posterior_predictive",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "idata_pymc3.observed_data",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "idata_pymc3.constant_data",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "idata_pymc3.prior",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "idata_pymc3.predictions",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 160002
    },
    {
      "source": "idata_pymc3.predictions_constant_data",
      "names": [],
      "example": {
        "document": "schema/PyMC3_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pymc3",
        "headings": [
          "Example of InferenceData schema in PyMC3"
        ]
      },
      "doc_lineno": 170002
    }
  ],
  "schema/PyStan_schema_example": [
    {
      "source": "import xgen as xg\nimport pystan\nimport pandas as pd\nimport numpy as np\nimport xarray\n\nxarray.set_options(display_style=\"html\");",
      "names": [
        {
          "import_components": [
            "pandas"
          ],
          "code_str": "pandas",
          "lineno": 3,
          "end_lineno": 3,
          "context": "import_target",
          "resolved_location": "pandas"
        },
        {
          "import_components": [
            "xarray"
          ],
          "code_str": "xarray",
          "lineno": 5,
          "end_lineno": 5,
          "context": "import_target",
          "resolved_location": "xarray"
        },
        {
          "import_components": [
            "xarray",
            "set_options"
          ],
          "code_str": "xarray.set_options",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "xarray.set_options"
        }
      ],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 20002
    },
    {
      "source": "# read data\ndata = pd.read_csv(\"linear_regression_data.csv\", index_col=0)\ntime_since_joined = data.time.values\nslack_comments = data.comments.values\ngithub_commits = data.commits.values\nnames = data.index.values\nN = len(names)\ndata",
      "names": [
        {
          "import_components": [
            "pandas",
            "read_csv"
          ],
          "code_str": "pd.read_csv",
          "lineno": 2,
          "end_lineno": 2,
          "context": "none",
          "resolved_location": "pandas.read_csv"
        },
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 7,
          "end_lineno": 7,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 30002
    },
    {
      "source": "# data for out of sample predictions\ncandidate_devs = [\"Francis\", \"Gerard\"]\ncandidate_devs_time = np.array([3.6, 5.1])\nN_pred = len(candidate_devs)",
      "names": [
        {
          "import_components": [
            "len"
          ],
          "code_str": "len",
          "lineno": 4,
          "end_lineno": 4,
          "context": "none",
          "resolved_location": "len"
        }
      ],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 40002
    },
    {
      "source": "linreg_prior_code = \"\"\"\ndata {\n  int<lower=0> N;\n  real time_since_joined[N];\n}\n\ngenerated quantities {\n    real b0;\n    real b1;\n    real log_b_sigma;\n    real<lower=0> b_sigma;\n    \n    real c0;\n    real c1;\n    real log_c_sigma;\n    real<lower=0> c_sigma;\n    \n    vector[N] slack_comments_hat;\n    vector[N] github_commits_hat;\n    \n    b0 = normal_rng(0,200);\n    b1 = normal_rng(0,200);\n    b_sigma = abs(normal_rng(0,300));\n    log_b_sigma = log(b_sigma);\n    \n    c0 = normal_rng(0,10);\n    c1 = normal_rng(0,10);\n    c_sigma = fabs(normal_rng(0,6));\n    log_c_sigma = log(b_sigma);\n    \n    for (n in 1:N) {\n        slack_comments_hat[n] = normal_rng(b0 + b1 * time_since_joined[n], b_sigma);\n        github_commits_hat[n] = normal_rng(c0 + c1 * time_since_joined[n], c_sigma);\n    }\n}\n\"\"\"\nsm_prior = pystan.StanModel(model_code=linreg_prior_code)",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 50002
    },
    {
      "source": "linreg_prior_data_dict = {\"N\": N, \"time_since_joined\": time_since_joined}\nprior = sm_prior.sampling(\n    data=linreg_prior_data_dict, iter=150, chains=1, algorithm=\"Fixed_param\", warmup=0\n)",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 60002
    },
    {
      "source": "linreg_code = \"\"\"\ndata {\n  int<lower=0> N;\n  vector<lower=0>[N] time_since_joined;\n  vector<lower=0>[N] slack_comments;\n  vector<lower=0>[N] github_commits;\n  \n  \n  // out of sample prediction\n  int<lower=0> N_pred;\n  vector<lower=0>[N_pred] time_since_joined_pred;\n}\n\nparameters {\n  real b0;\n  real b1;\n  real log_b_sigma;\n  \n  real c0;\n  real c1;\n  real log_c_sigma;\n}\n\ntransformed parameters {\n  real<lower=0> b_sigma = exp(log_b_sigma);\n  real<lower=0> c_sigma = exp(log_c_sigma);\n}\n\nmodel {\n  b0 ~ normal(0,200);\n  b1 ~ normal(0,200);\n  b_sigma ~ normal(0,300);\n  slack_comments ~ normal(b0 + b1 * time_since_joined, b_sigma);\n  github_commits ~ normal(c0 + c1 * time_since_joined, c_sigma);\n  \n}\n\ngenerated quantities {\n    // elementwise log likelihood\n    vector[N] log_likelihood_slack_comments;\n    vector[N] log_likelihood_github_commits;\n    \n    // posterior predictive\n    vector[N] slack_comments_hat;\n    vector[N] github_commits_hat;\n    \n    // out of sample prediction\n    vector[N_pred] slack_comments_pred;\n    vector[N_pred] github_commits_pred;\n    \n    // posterior predictive\n    for (n in 1:N) {\n        log_likelihood_slack_comments[n] = normal_lpdf(slack_comments[n] | b0 + b1 * time_since_joined[n], b_sigma);\n        slack_comments_hat[n] = normal_rng(b0 + b1 * time_since_joined[n], b_sigma);\n        \n        log_likelihood_github_commits[n] = normal_lpdf(github_commits[n] | c0 + c1 * time_since_joined[n], c_sigma);\n        github_commits_hat[n] = normal_rng(c0 + c1 * time_since_joined[n], c_sigma);\n    }\n    \n    // out of sample prediction\n    for (n in 1:N_pred) {\n        slack_comments_pred[n] = normal_rng(b0 + b1 * time_since_joined_pred[n], b_sigma);\n        github_commits_pred[n] = normal_rng(c0 + c1 * time_since_joined_pred[n], c_sigma);\n    }\n}\n\"\"\"\nsm = pystan.StanModel(model_code=linreg_code)",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 70002
    },
    {
      "source": "linreg_data_dict = {\n    \"N\": N,\n    \"slack_comments\": slack_comments,\n    \"github_commits\": github_commits,\n    \"time_since_joined\": time_since_joined,\n    \"N_pred\": N_pred,\n    \"time_since_joined_pred\": candidate_devs_time,\n}\nposterior = sm.sampling(data=linreg_data_dict, iter=200, chains=4)",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 80002
    },
    {
      "source": "idata_stan = az.from_pystan(\n    posterior=posterior,\n    prior=prior,\n    posterior_predictive=[\"slack_comments_hat\", \"github_commits_hat\"],\n    prior_predictive=[\"slack_comments_hat\", \"github_commits_hat\"],\n    observed_data=[\"slack_comments\", \"github_commits\"],\n    constant_data=[\"time_since_joined\"],\n    log_likelihood={\n        \"slack_comments\": \"log_likelihood_slack_comments\",\n        \"github_commits\": \"log_likelihood_github_commits\",\n    },\n    predictions=[\"slack_comments_pred\", \"github_commits_pred\"],\n    predictions_constant_data=[\"time_since_joined_pred\"],\n    coords={\"developer\": names, \"candidate developer\": candidate_devs},\n    dims={\n        \"slack_comments\": [\"developer\"],\n        \"github_commits\": [\"developer\"],\n        \"slack_comments_hat\": [\"developer\"],\n        \"github_commits_hat\": [\"developer\"],\n        \"time_since_joined\": [\"developer\"],\n        \"slack_comments_pred\": [\"candidate developer\"],\n        \"github_commits_pred\": [\"candidate developer\"],\n        \"time_since_joined_pred\": [\"candidate developer\"],\n    },\n)",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 90002
    },
    {
      "source": "idata_stan",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 100002
    },
    {
      "source": "idata_stan.posterior",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 120002
    },
    {
      "source": "idata_stan.sample_stats",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 130002
    },
    {
      "source": "idata_stan.log_likelihood",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 140002
    },
    {
      "source": "idata_stan.posterior_predictive",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 150002
    },
    {
      "source": "idata_stan.observed_data",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 160002
    },
    {
      "source": "idata_stan.constant_data",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 170002
    },
    {
      "source": "idata_stan.prior",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 180002
    },
    {
      "source": "idata_stan.sample_stats_prior",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 190002
    },
    {
      "source": "idata_stan.prior_predictive",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 200002
    },
    {
      "source": "idata_stan.predictions",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 210002
    },
    {
      "source": "idata_stan.predictions_constant_data",
      "names": [],
      "example": {
        "document": "schema/PyStan_schema_example",
        "ref_id": "example-of-inferencedata-schema-in-pystan",
        "headings": [
          "Example of InferenceData schema in PyStan"
        ]
      },
      "doc_lineno": 220002
    }
  ],
  "schema/schema": []
}